<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>《统计学习方法》笔记(一) - 已停更的小博客</title><meta name=renderer content=webkit><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=MobileOptimized content=width><meta name=HandheldFriendly content=true><meta name=applicable-device content=pc,mobile><meta name=theme-color content=#f8f5ec><meta name=msapplication-navbutton-color content=#f8f5ec><meta name=apple-mobile-web-app-capable content=yes><meta name=apple-mobile-web-app-status-bar-style content=#f8f5ec><meta name=mobile-web-app-capable content=yes><meta name=author content=Quanyin><meta name=description content=本文是在学习李航老师的《统计学习方法》时做的学习笔记系列的第一篇：概论><meta name=keywords content="Machine Learning,统计学习方法,笔记,机器学习"><link rel=canonical href=/2018/statistical-learning-method-chpt-1/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.css media=screen crossorigin=anonymous><meta property=og:title content=《统计学习方法》笔记(一)><meta property=og:description content=本文是在学习李航老师的《统计学习方法》时做的学习笔记系列的第一篇：概论><meta property=og:type content=article><meta property=og:url content=/2018/statistical-learning-method-chpt-1/><meta property=article:published_time content=2018-03-20T18:25:08&#43;08:00><meta property=article:modified_time content=2020-05-07T17:24:00&#43;08:00><meta itemprop=name content=《统计学习方法》笔记(一)><meta itemprop=description content=本文是在学习李航老师的《统计学习方法》时做的学习笔记系列的第一篇：概论><meta itemprop=datePublished content=2018-03-20T18:25:08&#43;08:00><meta itemprop=dateModified content=2020-05-07T17:24:00&#43;08:00><meta itemprop=wordCount content=3573><meta itemprop=keywords content="Machine Learning,"><meta name=twitter:card content=summary><meta name=twitter:title content=《统计学习方法》笔记(一)><meta name=twitter:description content=本文是在学习李航老师的《统计学习方法》时做的学习笔记系列的第一篇：概论><script>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-126038371-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script async src=//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:"ca-pub-4469282388984999",enable_page_level_ads:true});</script><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Blog</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=/>主页</a><li class=mobile-menu-item><a class=menu-item-link href=/notice/>通知</a><li class=mobile-menu-item><a class=menu-item-link href=/post/>时光机</a><li class=mobile-menu-item><div class=mobile-menu-parent><span class=mobile-submenu-open></span><a href=/categories/>分类</a></div><ul class=mobile-submenu-list><li><a href=/categories/%E7%AC%94%E8%AE%B0>笔记</a><li><a href=/categories/%E7%BC%96%E7%A8%8B>编程</a><li><a href=/categories/%E7%A7%91%E7%A0%94>科研</a><li><a href=/categories/%E5%AD%A6%E4%B9%A0>学习</a><li><a href=/categories/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86>错误处理</a></ul><li class=mobile-menu-item><a class=menu-item-link href=/about/>关于我</a></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>Blog</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>主页</a><li class=menu-item><a class=menu-item-link href=/notice/>通知</a><li class=menu-item><a class=menu-item-link href=/post/>时光机</a><li class=menu-item><a class="menu-item-link menu-parent" href=/categories/>分类</a><ul class=submenu><li><a href=/categories/%E7%AC%94%E8%AE%B0>笔记</a><li><a href=/categories/%E7%BC%96%E7%A8%8B>编程</a><li><a href=/categories/%E7%A7%91%E7%A0%94>科研</a><li><a href=/categories/%E5%AD%A6%E4%B9%A0>学习</a><li><a href=/categories/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86>错误处理</a></ul><li class=menu-item><a class=menu-item-link href=/about/>关于我</a></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>《统计学习方法》笔记(一)</h1><div class=post-meta><time datetime=2018-03-20 class=post-time>2018-03-20</time><div class=post-category><a href=/categories/%E7%AC%94%E8%AE%B0/>笔记</a></div><span class=more-meta>约 3573 字</span>
<span class=more-meta>预计阅读 8 分钟</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#一-统计学习相关概念>一、统计学习相关概念</a><ul><li><a href=#1-1-统计学习>1.1 统计学习</a><ul><li><a href=#特点>特点</a><li><a href=#对象>对象</a><li><a href=#基本假设>基本假设</a><li><a href=#目的>目的</a><li><a href=#方法>方法</a></ul><li><a href=#1-2-监督学习>1.2 监督学习</a><ul><li><a href=#输入空间-特征空间与输出空间>输入空间、特征空间与输出空间</a><li><a href=#联合概率分布>联合概率分布</a><li><a href=#假设空间>假设空间</a><li><a href=#分类>分类</a></ul></ul><li><a href=#二-统计学习三要素>二、统计学习三要素</a><ul><li><a href=#2-1-模型>2.1 模型</a><li><a href=#2-2-策略>2.2 策略</a><ul><li><a href=#损失函数>损失函数</a><li><a href=#风险函数>风险函数</a><li><a href=#经验风险>经验风险</a><li><a href=#策略1-经验风险最小化>策略1：经验风险最小化</a><li><a href=#策略2-结构风险最小化>策略2：结构风险最小化</a></ul><li><a href=#2-3-算法>2.3 算法</a></ul><li><a href=#三-模型的评估与选择>三、模型的评估与选择</a><ul><li><a href=#3-1-误差>3.1 误差</a><li><a href=#3-2-正则化>3.2 正则化</a><li><a href=#3-3-交叉验证>3.3 交叉验证</a><ul><li><a href=#简单交叉验证>简单交叉验证</a><li><a href=#s-折交叉验证>S 折交叉验证</a><li><a href=#留一折交叉验证>留一折交叉验证</a></ul><li><a href=#3-4-泛化能力>3.4 泛化能力</a><ul><li><a href=#泛化误差>泛化误差</a><li><a href=#泛化误差上界>泛化误差上界</a></ul><li><a href=#3-5-模型分类>3.5 模型分类</a></ul><li><a href=#四-统计学习方法的应用>四、统计学习方法的应用</a><ul><li><a href=#4-1-分类问题>4.1 分类问题</a><li><a href=#4-2-标注问题>4.2 标注问题</a><li><a href=#4-3-回归问题>4.3 回归问题</a></ul><li><a href=#五-习题解答>五、习题解答</a><li><a href=#参考>参考</a></ul></ul></nav></div></div><div class=post-content><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-4469282388984999 data-ad-slot=4019390506 data-ad-format=link data-full-width-responsive=true></ins><h2 id=一-统计学习相关概念>一、统计学习相关概念</h2><h3 id=1-1-统计学习>1.1 统计学习</h3><p>统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的门
学科，也称为统计机器学习。<h4 id=特点>特点</h4><ul><li>以计算机及网络为平台，是建立在计算机及网络之上的<li>以数据为研究对象，是数据驱动的学科<li>目的是对数据进行预测与分析<li>以方法为中心，统计学习方法构建模型并应用模型进行预测与分析<li>是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多领域的交叉学科</ul><h4 id=对象>对象</h4><p>统计学习的对象是数据。它从数据出发，提取数据的特征，抽象出数据的模型，发现数
中的知识，又回到对数据的预测与分析中去。<h4 id=基本假设>基本假设</h4><p>统计学习关于数据的基本假设是同类数据具有一定的统计规律。这是统计学习的前提。<h4 id=目的>目的</h4><p>统计学习用于对数据的进行预测与分析，特别是对未知数据进行预测与分析，是通过构建
概率统计模型实现的。统计学习总的目标就是考虑学习什么样的模型和如何学习模型，使
模型能对数据进行准确的预测与分析，同时也要尽可能的提高学习效率。<h4 id=方法>方法</h4><p>统计学习的方法是基于数据构建统计模型从而对数据进行预测与分析的。统计学习由监
学习，非监督学习，半监督学习和强化学习等组成。<p>以监督学习为例，统计学习方法是从给定的、有限的、用于学习的训练数据集出发，假
数据是独立同分布产生的；并且假设要学习的模型属于某个函数集合，成为假设空间；
应用某个评价准则，从假设空间中选取一个最优的模型，使它对已知训练数据和未知测试
数据在给定的评价标准下有最优的预测；最优模型的选取由算法实现。<p>实现统计学习方法的步骤如下：<ol><li>得到一个有限的训练数据集合；<li>确定包含所有可能的模型的假设空间，即学习模型的集合；<li>确定模型选择的准则，即学习的策略；<li>实现求解最优模型的算法，即学习的算法；<li>通过学习方法选择最优模型；<li>利用学习的最优模型对新数据进行预测或分析。</ol><h3 id=1-2-监督学习>1.2 监督学习</h3><h4 id=输入空间-特征空间与输出空间>输入空间、特征空间与输出空间</h4><p>在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间与输出空间。每个具
体的输入是实例，通常由特征向量表示，此时，所有向量存在的空间称为特征空间。<p>在监督学习过程中，将输入与输出看成是定义在输入(特征空间)与输出空间上的随机变量取值。输入、输出变量用大写字母 <code>X</code> 和 <code>Y</code> 表示，输入输出变量的取值用小写字母 <code>x</code> 和 <code>y</code> 表示。<h4 id=联合概率分布>联合概率分布</h4><p>监督学习关于数据的基本假设输入与输出的随机变量 <code>X</code> 和 <code>Y</code> 遵循联合分布概率 <code>P(X,Y)</code>.<h4 id=假设空间>假设空间</h4><p>监督学习的目的是在于学习一个由输入到输出的映射，这一映射由模型来表示，模型属于
由输入空间到输出空间的映射的集合，称之为假设空间。<h4 id=分类>分类</h4><table><thead><tr><th align=center>输入变量<th align=center>输出变量<th align=center>预测问题类型<tbody><tr><td align=center>连续变量<td align=center>连续变量<td align=center>回归问题<tr><td align=center>连续变量<td align=center>有限个离散变量<td align=center>分类问题<tr><td align=center>变量序列<td align=center>变量序列<td align=center>标注问题</table><h2 id=二-统计学习三要素>二、统计学习三要素</h2><p><font size=6px><strong><center>方法 = 模型 + 策略 + 算法</center></strong></font><h3 id=2-1-模型>2.1 模型</h3><p>模型是所要学习的条件概率分布 $ Y=f(x) $ 或 $ P(Y) $<p>模型的假设空间是所有可能的条件概率分布或决策函数。<p>决策函数的集合 $ F=\{f|Y=f(x)\} $ 或 $ F=\{P|P(Y|X)\} $<p>参数空间 <code>$ F=\{f|Y=f_\theta(X),\theta \in \text{R}^{n}\} $</code>
或 <code>$ F=\{P|P_\theta(Y|X),\theta \in {{\text{R}}^{n}}\} $</code><h3 id=2-2-策略>2.2 策略</h3><h4 id=损失函数>损失函数</h4><p>损失函数度量模型一次预测的好坏，是f(x)和Y的非负实值函数，记作$ L(Y,f(x)) $。损失
函数越小，模型就越好。统计学习常用的损失函数有以下几种：<ol><li><p>0-1损失函数
<code>$$ L(Y,f(x))=I(Y=f(x))= \begin{cases}
0,\quad Y\ne f(x) \\
1, \quad Y=f(x)
\end{cases} $$</code><li><p>平方损失函数
<code>$$ L(Y,f(x))= (Y-f(X))^2 $$</code><li><p>绝对损失函数
<code>$$ L(Y,f(x))= |Y-f(X)| $$</code><li><p>对数损失函数或对数似然损失函数
<code>$$ L(Y,P(Y|X))= -logP(Y|X) $$</code></ol><h4 id=风险函数>风险函数</h4><p>风险函数度量平均意义下的模型预测的好坏。由于模型的输入、输出$ (X,Y) $是随机变量，
服从联合分布$ P(X,Y) $，所以损失函数的期望是：
<code>$$ R_{exp}(f) = E_p[L(Y, f(X))]=\int\limits_{x \times y} L(y,f(x))P(x,y) dxdy $$</code>
这是理论上模型<code>$ f(x) $</code>关于联合分布<code>$ P(X,Y) $</code>的平均意义下的损失，称为风险函数
或期望损失。<h4 id=经验风险>经验风险</h4><p>对给定的训练集 <code>$ T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\} $</code>，模型<code>$ f(x) $</code> 关于训练集的平均损失称为经验风险或经验损失，记作<code>$ R_{emp} $</code>:<code>$$ R_{emp}(f)=\frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i)) $$</code>
期望风险<code>$ R_{exp}(f) $</code> 是模型关于联合分布的期望损失，经验风险<code>$ R_{emp}(f) $</code> 是模型关于训练样本的平均损失。当<code>$ N $</code>趋于无穷时，经验风险趋于期望风险。<h4 id=策略1-经验风险最小化>策略1：经验风险最小化</h4><p>经验风险最小化的策略认为：经验风险最小的模型是最优的模型，则求最优模型就是求解最优化问题：<code>$$ \min\limits_{f \in F} \frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i)) $$</code><h4 id=策略2-结构风险最小化>策略2：结构风险最小化</h4><p>结构风险最小化是为了防止过拟合而提出的策略，结构风险最小化等价于正则化。在经验风险上加上表示模型复杂度的正则化项或罚项。结构风险最小化的策略认为结构风险最小的模型是最优的模型，求最优模型即求解最优化问题：
<code>$$ \min\limits_{f \in F} \frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i))+\lambda J(f) $$</code><h3 id=2-3-算法>2.3 算法</h3><p>算法是指学习模型的具体计算方法，统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的算法。<h2 id=三-模型的评估与选择>三、模型的评估与选择</h2><h3 id=3-1-误差>3.1 误差</h3><p>训练误差是模型<code>$ Y={\hat{f}(X)} $</code>关于训练数据集的平均损失：<code>$$ R_{emp}(\hat{f}) =\frac{1}{N}\sum\limits_{i=1}^NL(y_i,\hat{f}(x_i)) $$</code>
测试误差是关于测试数据集的平均误差。<code>$$ e_{test}(\hat{f}) =\frac{1}{N’}\sum\limits_{i=1}^{N’}L(y_i,\hat{f}(x_i)) $$</code>当损失函数是0-1损失时，则变为了测试数据集的误差率。<h3 id=3-2-正则化>3.2 正则化</h3><p>模型选择的典型方法是正则化，正则化是结构风险最小化策略的实现，是在经验风险上加上一个正则化项或罚项。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。正则化项科研是模型参数向量的范数。一般具有如下形式：
<code>$$ \min\limits_{f \in F} \underbrace{\frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i))}_\text{经验风险}+\underbrace{\overbrace{\lambda}^\text{&gt;0,调节参数} J(f)}_\text{正则化项} $$</code>
正则化项对应于模型的先验概率，正则化的作用是选择经验风险与模型复杂度同时较小的模型，符合奥卡姆剃刀原理：在所有可能选择的模型中，能够很好解释已知数据并且充分简单才是最好的模型，也就是应该选择的模型。<h3 id=3-3-交叉验证>3.3 交叉验证</h3><p>如果给定的样本数据充足，进行模型选择的一种简单的方式是随机的将数据集切分为三部分，分别为训练集、验证集和测试集。训练集用来训练模型，验证集用于模型选择，测试集用于最终对学习方法的评估。在学习的的不同复杂度的模型中，选择对验证集有最小预测误差的模型。<p>在许多实际中，数据是不充分的，可以选择交叉验证的方法，其基本想法是重复的使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复的进行训练、测试和模型选择。<h4 id=简单交叉验证>简单交叉验证</h4><p>简单交叉验证方法是：先随机的将已给数据分为两部分，一部分作为训练集，另一部分作为测试集；然后用训练集在各种条件下训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。<h4 id=s-折交叉验证>S 折交叉验证</h4><p>应用最多，方法为：首先随机的将已给数据切分为 S 个互不相交的大小相同的子集；然后利用 S-1 个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的 S 种选择重复进行；最后选出 S 次评测中平均测试误差最小的模型。<h4 id=留一折交叉验证>留一折交叉验证</h4><p>S 折交叉验证的特殊情形是 S=N，称为留一折交叉验证，往往在数据极度匮乏下使用。<h3 id=3-4-泛化能力>3.4 泛化能力</h3><h4 id=泛化误差>泛化误差</h4><p>学习方法的泛化能力是指由该学习方法得到的模型对未知数据的预测能力，是学习方法本质上重要的性质。泛化误差的定义为学到的模型对未知数据预测的误差，即所学习到的模型的期望风险：
<code>$$ R_{exp}(\hat{f}) = E_p[L(Y, \hat{f}(X))]=\int\limits_{x \times y} L(y,\hat{f}(x))P(x,y) dxdy $$</code><h4 id=泛化误差上界>泛化误差上界</h4><p>定理：对二分类问题，当假设空间是有限个函数的集合<code>$ F=\{f_1,f_2,\dots ,f_d \} $</code>时，对任意一个函数<code>$ f \in F $</code>，至少以概率<code>$ 1-\delta $</code>，以下等式成立：
<code>$$ R(f) \le \hat{R}(f)+\varepsilon (d,N,\delta) $$</code>
其中:<code>$$ \varepsilon (d,N,\delta) = \sqrt{\frac{1}{N}(log d + log{\frac{1}{\delta}})} $$</code><h3 id=3-5-模型分类>3.5 模型分类</h3><p>监督学习方法可以分为生成方法和判别方法，对应的模型为生成模型和判别模型。<p>生成方法由数据学习联合概率分布，然后求出联合概率分布作为预测的模型，即生成模型(表示给定输入产生输出的关系)：<code>$$ P(Y|X)=\frac{P(X,Y)}{P(X)} $$</code>
判别方法由数据直接学习决策函数或者条件概率分布作为预测的模型，即判别模型。判别方法关心的是对给定的输入，应该预测什么样的输出。<h2 id=四-统计学习方法的应用>四、统计学习方法的应用</h2><h3 id=4-1-分类问题>4.1 分类问题</h3><p>在监督学习中，当输出变量取有限个离散值时，预测问题便成为分类问题。分类问题包含学习和输出两个过程。<p>二类分类问题常用的评价指标是精确率和召回率。通常以关注的类为正类，其他类为负类，分类器在测试数据集上的预测或正确或不正确，4种情况出现的总数记为：<ul><li>TP —— 将正类预测为正类数<li>FN —— 将正类预测为负类数<li>FP —— 将负类预测为正类数<li>TN —— 将负类预测为负类数</ul><p>则，精确率的定义为：<code>$ P = \frac{TP}{TP+FP} $</code>
召回率的定义为 <code>$ R = \frac{TP}{TP+FN} $</code>，以及还有F值，二者的调和均值。<p>常用方法：k 近邻法，感知机，朴素贝叶斯法，决策树法，逻辑斯谛回归模型，支持向量机，提升方法，贝叶斯网络，神经网络等。<h3 id=4-2-标注问题>4.2 标注问题</h3><p>标注问题的输入是一个观测序列，输出是一个标记序列或者状态序列。评价指标与分类问题一样，常用的方法有隐马尔科夫模型，条件随机场。<h3 id=4-3-回归问题>4.3 回归问题</h3><p>回归用于预测输入变量和输出变量之间的关系，等价于函数拟合。<h2 id=五-习题解答>五、习题解答</h2><h2 id=参考>参考</h2><ul><li>李航，统计学习方法，清华大学出版社</ul><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-4469282388984999 data-ad-slot=5357438236></ins><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-4469282388984999 data-ad-slot=5625031544 data-ad-format=auto data-full-width-responsive=true></ins></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>Quanyin</span><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2020-05-07</span><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content>本博客所有文章除特别声明外，均采用 <a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>(CC) BY-NC-SA 4.0 </a>许可协议。转载请注明作者和出处并告知</span></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/img/reward/WechatPay.png>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/img/reward/AliPay.png>
<span>支付宝打赏</span></label></div></div><footer class=post-footer><div class=post-tags><a href=/tags/machine-learning/>Machine Learning</a></div><nav class=post-nav><a class=prev href=/2018/statistical-learning-method-chpt-2/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">《统计学习方法》笔记(二)</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/2018/theme-preview/><span class="next-text nav-default">Theme Preview | 主题预览</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"/></svg></i></a></nav></footer></article><div class="post bg-white"><div id=comments></div><script src=//cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=//unpkg.com/valine/dist/Valine.min.js></script><script>if(window.location.hash){var checkExist=setInterval(function(){if($(window.location.hash).length){$('html, body').animate({scrollTop:$(window.location.hash).offset().top-90},700);clearInterval(checkExist);}},10);}</script><script>new Valine({el:'#comments',appId:'aTnk2nRIOVuFeXVYCRqOhEQ1-MdYXbMMI',appKey:'fPBawjKkMiA8biHbwoDim1mJ',notify:false,verify:false,avatar:'mm',placeholder:'说点什么吧',visitor:false});</script></div></div></div></main><footer id=footer class=footer><div class=icon-links><a href=/index.xml rel="noopener alternate" type=application/rss&#43;xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 0 1 140.501333 140.586667A140.928 140.928.0 0 1 140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2017 -
2020
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>Quanyin</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777v0zm0 0"/></svg></i></div></div><script src=/lib/jquery/jquery-3.2.1.min.js></script><script src=/lib/slideout/slideout-1.0.1.min.js></script><script src=/js/main.js crossorigin=anonymous></script><script>window.MathJax={showProcessingMessages:false,messageStyle:'none'};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script src=/js/load-photoswipe.js></script><script src=/lib/photoswipe/photoswipe.min.js></script><script src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script>(adsbygoogle=window.adsbygoogle||[]).push({});</script>