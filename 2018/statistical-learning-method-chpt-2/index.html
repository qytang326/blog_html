<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>《统计学习方法》笔记(二) - 已停更的小博客</title><meta name=renderer content=webkit><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=MobileOptimized content=width><meta name=HandheldFriendly content=true><meta name=applicable-device content=pc,mobile><meta name=theme-color content=#f8f5ec><meta name=msapplication-navbutton-color content=#f8f5ec><meta name=apple-mobile-web-app-capable content=yes><meta name=apple-mobile-web-app-status-bar-style content=#f8f5ec><meta name=mobile-web-app-capable content=yes><meta name=author content=Quanyin><meta name=description content=本文是在学习李航老师的《统计学习方法》时做的学习笔记系列的第二篇：第二章-感知机><meta name=keywords content="Machine Learning,统计学习方法,笔记,机器学习,感知机"><meta name=generator content="Hugo 0.55.6"><link rel=canonical href=/2018/statistical-learning-method-chpt-2/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.af20b78e95c84de86b00a0242a4a77bd2601700e1b250edf27537d957ac0041d.css integrity="sha256-ryC3jpXITehrAKAkKkp3vSYBcA4bJQ7fJ1N9lXrABB0=" media=screen crossorigin=anonymous><meta property=og:title content=《统计学习方法》笔记(二)><meta property=og:description content=本文是在学习李航老师的《统计学习方法》时做的学习笔记系列的第二篇：第二章-感知机><meta property=og:type content=article><meta property=og:url content=/2018/statistical-learning-method-chpt-2/><meta property=article:published_time content=2018-03-26T16:23:04&#43;08:00><meta property=article:modified_time content=2020-05-07T17:24:00&#43;08:00><meta itemprop=name content=《统计学习方法》笔记(二)><meta itemprop=description content=本文是在学习李航老师的《统计学习方法》时做的学习笔记系列的第二篇：第二章-感知机><meta itemprop=datePublished content=2018-03-26T16:23:04&#43;08:00><meta itemprop=dateModified content=2020-05-07T17:24:00&#43;08:00><meta itemprop=wordCount content=1530><meta itemprop=keywords content="Machine Learning,"><meta name=twitter:card content=summary><meta name=twitter:title content=《统计学习方法》笔记(二)><meta name=twitter:description content=本文是在学习李航老师的《统计学习方法》时做的学习笔记系列的第二篇：第二章-感知机><script>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-126038371-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script async src=//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:"ca-pub-4469282388984999",enable_page_level_ads:true});</script><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Blog</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=/>主页</a><li class=mobile-menu-item><a class=menu-item-link href=/notice/>通知</a><li class=mobile-menu-item><a class=menu-item-link href=/post/>时光机</a><li class=mobile-menu-item><div class=mobile-menu-parent><span class=mobile-submenu-open></span><a href=/categories/>分类</a></div><ul class=mobile-submenu-list><li><a href=/categories/%E7%AC%94%E8%AE%B0>笔记</a><li><a href=/categories/%E7%BC%96%E7%A8%8B>编程</a><li><a href=/categories/%E7%A7%91%E7%A0%94>科研</a><li><a href=/categories/%E5%AD%A6%E4%B9%A0>学习</a><li><a href=/categories/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86>错误处理</a></ul><li class=mobile-menu-item><a class=menu-item-link href=/about/>关于我</a></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>Blog</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>主页</a><li class=menu-item><a class=menu-item-link href=/notice/>通知</a><li class=menu-item><a class=menu-item-link href=/post/>时光机</a><li class=menu-item><a class="menu-item-link menu-parent" href=/categories/>分类</a><ul class=submenu><li><a href=/categories/%E7%AC%94%E8%AE%B0>笔记</a><li><a href=/categories/%E7%BC%96%E7%A8%8B>编程</a><li><a href=/categories/%E7%A7%91%E7%A0%94>科研</a><li><a href=/categories/%E5%AD%A6%E4%B9%A0>学习</a><li><a href=/categories/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86>错误处理</a></ul><li class=menu-item><a class=menu-item-link href=/about/>关于我</a></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>《统计学习方法》笔记(二)</h1><div class=post-meta><time datetime=2018-03-26 class=post-time>2018-03-26</time><div class=post-category><a href=/categories/%E7%AC%94%E8%AE%B0/>笔记</a></div><span class=more-meta>约 1530 字</span>
<span class=more-meta>预计阅读 4 分钟</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#一-感知机模型>一、感知机模型</a><ul><li><a href=#定义>定义</a><li><a href=#几何解释>几何解释</a></ul><li><a href=#二-感知机学习策略>二、感知机学习策略</a><li><a href=#三-感知机学习算法>三、感知机学习算法</a><ul><li><a href=#原始形式>原始形式</a><li><a href=#对偶形式>对偶形式</a><li><a href=#收敛性证明>收敛性证明</a></ul></ul></ul></nav></div></div><div class=post-content><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-4469282388984999 data-ad-slot=4019390506 data-ad-format=link data-full-width-responsive=true></ins><p>感知机是<code>二分类</code>的<code>线性</code>分类模型，其输入为实例的特征向量，输出为实例的类别，取 +1 和 -1 两值。感知机对应于输入空间(特征空间)中将实例划分为正负两例的<code>分离超平面</code>，属于<code>判别模型</code>。
感知机学习旨在求出将训练集进行线性划分的分离超平面，导入<code>基于误分类的损失函数</code>，利用
<code>梯度下降法</code>对损失函数进行极小化，求得感知机模型。感知机由 Rosonblatt 1957 年提出，是神经网络与支持向量机的基础。<h2 id=一-感知机模型>一、感知机模型</h2><h3 id=定义>定义</h3><p>假设输入空间(特征空间)是 $ X \in R^n $，输出空间是 $ Y={+1，-1} $.输入 $ x\in X $
表示实例的特征向量，对应于输入(特征)空间的点，输出 $ y \in Y $表示实例的类别。由输入空间到输出空间的如下函数$$ f(x)=sign(w\cdot x + b) $$称为感知机。其中，$ w $、$ b $ 为感知机模型参数，$ w \in R^n $ 叫做权值或者权值向量，$ b \in R $ 叫做偏置，$sign$是符号函数：<code>$$ sign(x)= \begin{cases} +1,\quad x \ge 0 \\ -1, \quad x &lt; 0 \end{cases} $$</code><p>感知机是一种线性分类模型，属于判别模型，其假设空间是定义在特征空间的所有线性分类模型或线性分类器，即函数集合<code>$\{f|f(x)=w\cdot x+b\}$</code><h3 id=几何解释>几何解释</h3><p><link rel=stylesheet href=/css/hugo-easy-gallery.css><div class=box><figure class="center lazyload" itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/img/post-content/statistic-learning-method/post-Lihang-chpt2-model.png alt=感知机模型></div><a href=/img/post-content/statistic-learning-method/post-Lihang-chpt2-model.png itemprop=contentUrl></a><figcaption><h4>感知机模型</h4></figcaption></figure></div><h2 id=二-感知机学习策略>二、感知机学习策略</h2><p>假设训练数据集是线性可分的(存在超平面将数据集的正负实例划分到超平面的两侧)，感知机的学习目标是求得一个能够将训练数据集正负实例点完全正确分开的分离超平面，需要确定一个学习策略，即定义(经验)损失函数并将其极小化。<p>损失函数的一个自然选择是误分类点的总数，然而这样的损失函数不是参数 $w,b$ 的连续可
导函数，不易优化。<p>损失函数的另一个选择是误分类点到超平面的总距离，这是感知机所采用的，忽略前面的 $w$ 的<code>$L_2$</code>范数，感知机 $sign
(w\cdot x+b)$ 学习的损失函数定义为$$ L(w,b)=-\sum\limits_{x_i \in M}y_i(w\cdot x_i +b) $$
其中，$M$为误分类点的集合，这个损失函数就是感知机学习的经验风险函数。<p>显然，上述损失函数是非负的，如果没有误分类点，损失函数值为0，并且损失函数 $L(w,b)$ 是
$w,b$的连续可导函数，感知机的学习策略是在假设空间中选取使损失函数 $L(w,b)$ 最小的模型参数 $w,b$。<h2 id=三-感知机学习算法>三、感知机学习算法</h2><p>感知机学习问题转化为求解损失函数的最优化问题，最优化的方法是随机梯度下降法。感知机的学习算法
是误分类驱动的，具体采用的随机梯度下降。首先，任意选取一个超平面，然后用梯度下降法
不端极小化目标函数，极小化过程中不是一次使所有误分类点的梯度下降，而是一次随机选取误分类点使其梯度下降。<h3 id=原始形式>原始形式</h3><p>输入：训练数据集<code>$ T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$</code>，其中，$x_i\in X=R^n$,
<code>$y_i \in Y=\{-1，+1\}, i=1,2,...,N$</code>,学习率 $\eta(0&lt;\eta\le 1)$;<p>输出：$w,b$,感知机模型 $f(x)=sign(w\cdot x + b)$.<ol><li>选取初值 $w_0,b_0$<li>在训练集中选取数据 $(x_i,y_i)$<li>若 $y_i(w\cdot x_i+b) \le 0$，则更新：<code>$$ w \gets w+\eta y_ix_i \\ b \gets b+\eta y_i $$</code><li>转至2，直至训练集没有误分类点。</ol><p>解释：当一个实例点被误分类时，即位于分离超平面错误一侧时，则调整 $w,b$ 的值，使分离超平面向该误分类的一侧移动，
以减少该误分类点与超平面的距离，直至超平面越过该误分类点使其被正确分类。<h3 id=对偶形式>对偶形式</h3><p>输入：线性可分的数据集<code>$ T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$</code>，其中 $x_i\in X=R^n$,
<code>$y_i \in Y=\{-1，+1\}, i=1,2,...,N$</code>,学习率 $\eta(0&lt;\eta\le 1)$;<p>输出：$\alpha,b$，感知机模型 <code>$f(x)=sign(\sum\limits_{j=1}^N{\alpha_jy_jx_jx+b})$</code>，
其中 $\alpha=(\alpha_1,\alpha_2,&hellip;,\alpha_N)^T$<ol><li>$\alpha \gets 0,b\gets 0$<li>在训练集上选取数据$(x_i,y_i)$<li>如果 <code>$y_i(\sum\limits_{j=1}^N{\alpha_jy_jx_j\cdot x_i+b}) \le 0 $</code>，则：
$$\alpha_i \gets \alpha_i +\eta$$
$$b \gets b+ \eta y_i$$<li>转至2，直至训练集没有误分类点。</ol><p>对偶形式中训练实例仅以内积的形式出现，可以预先将训练集中实例间的内积计算出来并以矩阵的
形式存储，即 Gram 矩阵：<code>$ G={[ x_i \cdot x_j ]}_{N \times N} $</code><h3 id=收敛性证明>收敛性证明</h3><p>从训练集线性可分出发，可以证明，具体证明过程从略。</p><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-4469282388984999 data-ad-slot=5357438236></ins><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-4469282388984999 data-ad-slot=5625031544 data-ad-format=auto data-full-width-responsive=true></ins></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>Quanyin</span><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2020-05-07</span><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content>本博客所有文章除特别声明外，均采用 <a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>(CC) BY-NC-SA 4.0 </a>许可协议。转载请注明作者和出处并告知</span></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/img/reward/WechatPay.png>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/img/reward/AliPay.png>
<span>支付宝打赏</span></label></div></div><footer class=post-footer><div class=post-tags><a href=/tags/machine-learning/>Machine Learning</a></div><nav class=post-nav><a class=prev href=/2018/statistical-learning-method-chpt-3/><i class="iconfont icon-left"></i><span class="prev-text nav-default">《统计学习方法》笔记(三)</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/2018/statistical-learning-method-chpt-1/><span class="next-text nav-default">《统计学习方法》笔记(一)</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class="iconfont icon-right"></i></a></nav></footer></article><div class="post bg-white"><script src=https://cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=https://unpkg.com/valine/dist/Valine.min.js></script><div id=vcomments></div><script>new Valine({el:'#vcomments',appId:'aTnk2nRIOVuFeXVYCRqOhEQ1-MdYXbMMI',appKey:'fPBawjKkMiA8biHbwoDim1mJ',avatar:'mm',placeholder:'说点什么吧',})</script></div></div></div></main><footer id=footer class=footer><div class=icon-links><a href=/index.xml rel="noopener alternate" type=application/rss&#43;xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 0 1 140.501333 140.586667A140.928 140.928.0 0 1 140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2017 -
2020
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>Quanyin</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777v0zm0 0"/></svg></i></div></div><script src=/lib/jquery/jquery-3.2.1.min.js></script><script src=/lib/slideout/slideout-1.0.1.min.js></script><script src="/dist/jane.min.js?v=2.7.0"></script><script>window.MathJax={showProcessingMessages:false,messageStyle:'none'};</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script src=/js/load-photoswipe.js></script><script src=/lib/photoswipe/photoswipe.min.js></script><script src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script>(adsbygoogle=window.adsbygoogle||[]).push({});</script>