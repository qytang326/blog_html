<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>这是一份你们需要的Windows版深度学习软件安装指南 - 陆家嘴之羊</title><meta name=renderer content=webkit><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=MobileOptimized content=width><meta name=HandheldFriendly content=true><meta name=applicable-device content=pc,mobile><meta name=theme-color content=#f8f5ec><meta name=msapplication-navbutton-color content=#f8f5ec><meta name=apple-mobile-web-app-capable content=yes><meta name=apple-mobile-web-app-status-bar-style content=#f8f5ec><meta name=mobile-web-app-capable content=yes><meta name=author content=Quanyin><meta name=description content="本文从最基本的依赖项开始,依次配置了 VS 2015、Anaconda 4.4.0、CUDA 8.0.61 和 cuDNN v5.1 等基本环境,然后再从 Keras 出发安装 Theano、TensorFlow 和 CNTK 以作为其后端.在完成配置深度学习框架后,本文分别利用这三个框架作为 Keras 后端在 CPU 和 GPU 上训练了一个标准的卷积神经网络,完成该简单的卷积网络也就意味着我们完成了深度学习环境的配置."><meta name=keywords content=技术博客><link rel=canonical href=/2017/deeplearning-on-windows/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.css media=screen crossorigin=anonymous><meta property=og:title content=这是一份你们需要的Windows版深度学习软件安装指南><meta property=og:description content="本文从最基本的依赖项开始,依次配置了 VS 2015、Anaconda 4.4.0、CUDA 8.0.61 和 cuDNN v5.1 等基本环境,然后再从 Keras 出发安装 Theano、TensorFlow 和 CNTK 以作为其后端.在完成配置深度学习框架后,本文分别利用这三个框架作为 Keras 后端在 CPU 和 GPU 上训练了一个标准的卷积神经网络,完成该简单的卷积网络也就意味着我们完成了深度学习环境的配置."><meta property=og:type content=article><meta property=og:url content=/2017/deeplearning-on-windows/><meta property=article:published_time content=2017-10-12T00:00:00&#43;00:00><meta property=article:modified_time content=2020-05-07T17:24:00&#43;08:00><meta itemprop=name content=这是一份你们需要的Windows版深度学习软件安装指南><meta itemprop=description content="本文从最基本的依赖项开始,依次配置了 VS 2015、Anaconda 4.4.0、CUDA 8.0.61 和 cuDNN v5.1 等基本环境,然后再从 Keras 出发安装 Theano、TensorFlow 和 CNTK 以作为其后端.在完成配置深度学习框架后,本文分别利用这三个框架作为 Keras 后端在 CPU 和 GPU 上训练了一个标准的卷积神经网络,完成该简单的卷积网络也就意味着我们完成了深度学习环境的配置."><meta itemprop=datePublished content=2017-10-12T00:00:00&#43;00:00><meta itemprop=dateModified content=2020-05-07T17:24:00&#43;08:00><meta itemprop=wordCount content=8057><meta itemprop=keywords content=Deep-Learning,Python,><meta name=twitter:card content=summary><meta name=twitter:title content=这是一份你们需要的Windows版深度学习软件安装指南><meta name=twitter:description content="本文从最基本的依赖项开始,依次配置了 VS 2015、Anaconda 4.4.0、CUDA 8.0.61 和 cuDNN v5.1 等基本环境,然后再从 Keras 出发安装 Theano、TensorFlow 和 CNTK 以作为其后端.在完成配置深度学习框架后,本文分别利用这三个框架作为 Keras 后端在 CPU 和 GPU 上训练了一个标准的卷积神经网络,完成该简单的卷积网络也就意味着我们完成了深度学习环境的配置."><script>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-126038371-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script async src=//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:"ca-pub-4469282388984999",enable_page_level_ads:true});</script><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>陆家嘴之羊</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=/>主页</a><li class=mobile-menu-item><a class=menu-item-link href=/notice/>通知</a><li class=mobile-menu-item><a class=menu-item-link href=/post/>时光机</a><li class=mobile-menu-item><div class=mobile-menu-parent><span class=mobile-submenu-open></span><a href=/categories/>分类</a></div><ul class=mobile-submenu-list><li><a href=/categories/%E7%AC%94%E8%AE%B0>笔记</a><li><a href=/categories/%E7%BC%96%E7%A8%8B>编程</a><li><a href=/categories/%E7%A7%91%E7%A0%94>科研</a><li><a href=/categories/%E5%AD%A6%E4%B9%A0>学习</a><li><a href=/categories/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86>错误处理</a></ul><li class=mobile-menu-item><a class=menu-item-link href=/about/>关于我</a></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>陆家嘴之羊</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>主页</a><li class=menu-item><a class=menu-item-link href=/notice/>通知</a><li class=menu-item><a class=menu-item-link href=/post/>时光机</a><li class=menu-item><a class="menu-item-link menu-parent" href=/categories/>分类</a><ul class=submenu><li><a href=/categories/%E7%AC%94%E8%AE%B0>笔记</a><li><a href=/categories/%E7%BC%96%E7%A8%8B>编程</a><li><a href=/categories/%E7%A7%91%E7%A0%94>科研</a><li><a href=/categories/%E5%AD%A6%E4%B9%A0>学习</a><li><a href=/categories/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86>错误处理</a></ul><li class=menu-item><a class=menu-item-link href=/about/>关于我</a></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>这是一份你们需要的Windows版深度学习软件安装指南</h1><div class=post-meta><time datetime=2017-10-12 class=post-time>2017-10-12</time><div class=post-category><a href=/categories/%E7%BC%96%E7%A8%8B/>编程</a>
<a href=/categories/%E7%AC%94%E8%AE%B0/>笔记</a></div><span class=more-meta>约 8057 字</span>
<span class=more-meta>预计阅读 17 分钟</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#依赖项>依赖项</a><li><a href=#硬件>硬件</a><li><a href=#安装步骤>安装步骤</a><ul><li><a href=#visual-studio-2015-community-edition-update-3-w-windows-kit-10-0-10240-0>Visual Studio 2015 Community Edition Update 3 w. Windows Kit 10.0.10240.0</a><li><a href=#anaconda-4-4-0-64-bit-python-3-6-tf-support-python-2-7-no-tf-support>Anaconda 4.4.0 (64-bit) (Python 3.6 TF support / Python 2.7 no TF support))</a><ul><li><a href=#创建-dlwin36-conda-环境>创建 <code>dlwin36</code> conda 环境</a></ul><li><a href=#cuda-8-0-61-64-bit>CUDA 8.0.61 (64-bit)</a><li><a href=#cudnn-v5-1-jan-20-2017-for-cuda-8-0>cuDNN v5.1 (Jan 20, 2017) for CUDA 8.0</a><li><a href=#安装-keras-2-0-5-和-theano0-9-0-与-libgpuarray>安装 Keras 2.0.5 和 Theano0.9.0 与 libgpuarray</a><li><a href=#installing-the-cntk-2-0-backend>Installing the CNTK 2.0 backend</a><li><a href=#安装-tensorflow-gpu-1-2-0-后端>安装 TensorFlow-GPU 1.2.0 后端</a><li><a href=#使用-conda-检查安装的软件包>使用 conda 检查安装的软件包</a><li><a href=#验证-theano-的安装>验证 Theano 的安装</a><li><a href=#检查系统环境变量>检查系统环境变量</a><li><a href=#使用-keras-验证-gpu-cudnn-的安装>使用 Keras 验证 GPU+cuDNN 的安装</a><ul><li><a href=#1-使用带-theano-后端的-keras>1.使用带 Theano 后端的 Keras</a><li><a href=#2-使用-tensorflow-后端的-keras>2. 使用 TensorFlow 后端的 Keras</a><li><a href=#3-使用-cntk-后端的-keras>3. 使用 CNTK 后端的 Keras</a></ul></ul><li><a href=#最后>最后</a><ul><li><a href=#参考>参考</a><li><a href=#致谢>致谢&hellip;</a><li><a href=#推荐阅读>推荐阅读</a><li><a href=#作者信息>作者信息</a><li><a href=#补充>补充</a></ul></ul></ul></nav></div></div><div class=post-content><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-4469282388984999 data-ad-slot=4019390506 data-ad-format=link data-full-width-responsive=true></ins><blockquote><p>本文经机器之心(微信公众号:almosthuman2014)授权转载,禁止二次转载.本文由机器之心编译,蒋思源、刘晓坤参与.<p>本文从最基本的依赖项开始,依次配置了 VS 2015、Anaconda 4.4.0、CUDA 8.0.61 和 cuDNN v5.1 等基本环境,然后再从 Keras 出发安装 Theano、TensorFlow 和 CNTK 以作为其后端.在完成配置深度学习框架后,本文分别利用这三个框架作为 Keras 后端在 CPU 和 GPU 上训练了一个标准的卷积神经网络,完成该简单的卷积网络也就意味着我们完成了深度学习环境的配置.</blockquote><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650731550&amp;amp;idx=1&amp;amp;sn=0ad49b4f74046456d806655b36659ba8&amp;amp;chksm=871b3060b06cb9761b6016c083413d33ec5333fd520deb1264aca45f469f1125d381376cf973&amp;scene=21##wechat_redirect" target=_blank>从零开始:深度学习软件环境安装指南</a>(Ubuntu)<li>本文GitHub地址:<a href=https://github.com/philferriere/dlwin target=_blank>https://github.com/philferriere/dlwin</a></ul><p>该配置版本最后更新的日期是今年七月,该更新版本允许本地使用 3 个不同的 GPU 加速后端,并添加对 MKL BLAS 库的支持.<p>目前有很多帮助我们在 Linux 或 Mac OS 上构建深度学习(DL)环境的指导文章,但很少有文章完整地叙述如何高效地在 Windows 10 上配置深度学习开发环境.此外,很多开发者安装 Windows 和 Ubuntu 双系统或在 Windows 上安装虚拟机以配置深度学习环境,但对于入门者来说,我们更希望还是直接使用 Windows 直接配置深度学习环境.因此,本文作者 Phil Ferriere 在 GitHub 上发布了该教程,他希望能从最基本的环境变量配置开始一步步搭建 Keras 深度学习开发环境.<p>如果读者希望在 Windows 10 上配置深度学习环境,那么本文将为大家提供很多有利的信息.<h2 id=依赖项>依赖项</h2><p>下面是我们将在 Windows 10(Version 1607 OS Build 14393.222)上配置深度学习环境所需要的工具和软件包:
1. Visual Studio 2015 Community Edition Update 3 w. Windows Kit 10.0.10240.0:用于其 C/C++编译器(而不是 IDE)和 SDK,选择该确定的版本是因为 CUDA 8.0.61 所支持的 Windows 编译器.<ol><li><p>Anaconda (64-bit) w. Python 3.6 (Anaconda3-4.4.0) [for Tensorflow support] or Python 2.7 (Anaconda2-4.4.0) [no Tensorflow support] with MKL:Anaconda 是一个开源的 Python 发行版本,其包含了 conda、Python、NumPy、SciPy 等 180 多个科学包及其依赖项,是一个集成开发环境.MKL 可以利用 CPU 加速许多线性代数运算.<li><p>CUDA 8.0.61 (64-bit):CUDA 是一种由 NVIDIA 推出的通用并行计算架构,该架构使 GPU 能够解决复杂的计算问题,该软件包能提供 GPU 数学库、显卡驱动和 CUDA 编译器等.<li><p>cuDNN v5.1 (Jan 20, 2017) for CUDA 8.0:用于加速卷积神经网络的运算.<li><p>Keras 2.0.5 with three different backends: Theano 0.9.0, Tensorflow-gpu 1.2.0, and CNTK 2.0:Keras 以 Theano、Tensorflow 或 CNTK 等框架为后端,并提供深度学习高级 API.使用不同的后端在张量数学计算等方面会有不同的效果</ol><h2 id=硬件>硬件</h2><ol><li>Dell Precision T7900, 64GB RAM<ul><li>Intel Xeon E5-2630 v4 @ 2.20 GHz (1 processor, 10 cores total, 20 logical processors)</ul><li>NVIDIA GeForce Titan X, 12GB RAM<ul><li>Driver version: 372.90 / Win 10 64</ul></ol><h2 id=安装步骤>安装步骤</h2><p>我们可能喜欢让所有的工具包和软件包在一个根目录下(如 <code>e:\toolkits.win</code>),所以在下文只要看到以<code>e:\toolkits.win</code>开头的路径,那么我们可能就需要小心不要覆盖或随意更改必要的软件包目录.<h3 id=visual-studio-2015-community-edition-update-3-w-windows-kit-10-0-10240-0>Visual Studio 2015 Community Edition Update 3 w. Windows Kit 10.0.10240.0</h3><p>下载 <a href=https://www.visualstudio.com/vs/older-downloads target=_blank>Visual Studio Community 2015 with Update 3 (x86)</a>.
&gt; Note that for downloading, a free <a href=https://www.visualstudio.com/dev-essentials/ target=_blank>Visual Studio Dev Essentials</a>
license or a full Visual Studio Subscription is required.<p>运行下载的软件包以安装 Visual Studio,可能我们还需要做一些额外的配置:<p><img src=/img/post-content/deeplearning-on-windows/vs2015-install-part1-2016-10.png alt><p><img src=/img/post-content/deeplearning-on-windows/vs2015-install-part2-2016-10.png alt><p><img src=/img/post-content/deeplearning-on-windows/vs2015-install-part3b-2016-10.png alt><p><img src=/img/post-content/deeplearning-on-windows/vs2015-install-part4b-2016-10.png alt><ol><li>基于我们安装 VS 2015 的地址,需要将 <code>C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin</code> 到 <code>PATH</code> 中.<li><p>定义系统环境变量(sysenv variable) <code>INCLUDE</code> 的值为:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><span class=lnt>1
</span></pre><td class=lntd><pre class=chroma>C:\Program Files (x86)\Windows Kits\10\Include\10.0.10240.0\ucrt</pre></table></div></div><li><p>定义系统环境变量 <code>LIB</code> 的值为:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><span class=lnt>1
</span></pre><td class=lntd><pre class=chroma>C:\Program Files (x86)\Windows Kits\10\Lib\10.0.10240.0\um\x64;C:\Program Files (x86)\Windows Kits\10\Lib\10.0.10240.0\ucrt\x64</pre></table></div></div></ol><blockquote><p>Reference Note: We couldn&rsquo;t run any Theano python files until we added the last two env variables above.
We would get a <code>c:\program files (x86)\microsoft visual studio 14.0\vc\include\crtdefs.h(10): fatal error C1083: Cannot open include file: 'corecrt.h': No such file or directory</code> error at compile time and missing <code>kernel32.lib uuid.lib ucrt.lib</code> errors at link time. True, you could probably run <code>C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\amd64\vcvars64.bat</code> (with proper params) every single time you open a MINGW cmd prompt, but, obviously, none of the sysenv vars would stick from one session to the next.</blockquote><h3 id=anaconda-4-4-0-64-bit-python-3-6-tf-support-python-2-7-no-tf-support>Anaconda 4.4.0 (64-bit) (Python 3.6 TF support / Python 2.7 no TF support))</h3><p>本教程最初使用的是 Python 2.7,而随着 TensorFlow 可作为 Keras 的后端,我们决定使用 Python 3.6 作为默认配置.因此,根据我们配置的偏好,可以设置 e:\toolkits.win\anaconda3-4.4.0 或 e:\toolkits.win\anaconda2-4.4.0 为安装 Anaconda 的文件夹名.<ul><li>下载 Python 3.6 版本的Anaconda <a href=https://repo.continuum.io/archive/Anaconda3-4.4.0-Windows-x86_64.exe target=_blank>here</a></ul><p><img src=/img/post-content/deeplearning-on-windows/anaconda-4.4.0-download-2017-07.png alt><ul><li>运行安装程序完成安装Anaconda:</ul><p><img src=/img/post-content/deeplearning-on-windows/anaconda-4.4.0-setup1-2017-07.jpg alt>
<img src=/img/post-content/deeplearning-on-windows/anaconda-4.4.0-setup2-2017-07.jpg alt><blockquote><p>如图,本教程选择了 <code>Advanced Options</code> 的第二个选项,但不一定是最好的.</blockquote><p><img src=/img/post-content/deeplearning-on-windows/anaconda-4.4.0-setup3-2017-07.jpg alt><ul><li>定义一下变量并更新 <code>PATH</code>:</ul><ol><li>定义系统环境(sysenv variable)变量 <code>PYTHON_HOME</code> 的值为 <code>e:\toolkits.win\anaconda3-4.4.0</code><li>添加 <code>%PYTHON_HOME%</code>, <code>%PYTHON_HOME%\Scripts</code>, 和 <code>%PYTHON_HOME%\Library\bin</code> 到 <code>PATH</code> 中去.</ol><h4 id=创建-dlwin36-conda-环境>创建 <code>dlwin36</code> conda 环境</h4><p>在安装 Anaconda 后,打开 Windows 命令窗口并执行:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=c1>##使用以下命令行创建环境</span>
$ conda create --yes -n dlwin36 numpy scipy mkl-service m2w64-toolchain libpython jupyter
Fetching package metadata ...........
Solving package specifications: .

Package plan <span class=k>for</span> installation in environment e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36:

The following NEW packages will be INSTALLED:

    bleach:                         <span class=m>1</span>.5.0-py36_0
    colorama:                       <span class=m>0</span>.3.9-py36_0
    decorator:                      <span class=m>4</span>.0.11-py36_0
    entrypoints:                    <span class=m>0</span>.2.2-py36_1
    html5lib:                       <span class=m>0</span>.999-py36_0
    icu:                            <span class=m>57</span>.1-vc14_0          <span class=o>[</span>vc14<span class=o>]</span>
    ipykernel:                      <span class=m>4</span>.6.1-py36_0
    ipython:                        <span class=m>6</span>.1.0-py36_0
    ipython_genutils:               <span class=m>0</span>.2.0-py36_0
    ipywidgets:                     <span class=m>6</span>.0.0-py36_0
    jedi:                           <span class=m>0</span>.10.2-py36_2
    jinja2:                         <span class=m>2</span>.9.6-py36_0
    jpeg:                           9b-vc14_0            <span class=o>[</span>vc14<span class=o>]</span>
    jsonschema:                     <span class=m>2</span>.6.0-py36_0
    jupyter:                        <span class=m>1</span>.0.0-py36_3
    jupyter_client:                 <span class=m>5</span>.1.0-py36_0
    jupyter_console:                <span class=m>5</span>.1.0-py36_0
    jupyter_core:                   <span class=m>4</span>.3.0-py36_0
    libpng:                         <span class=m>1</span>.6.27-vc14_0        <span class=o>[</span>vc14<span class=o>]</span>
    libpython:                      <span class=m>2</span>.0-py36_0
    m2w64-binutils:                 <span class=m>2</span>.25.1-5
    m2w64-bzip2:                    <span class=m>1</span>.0.6-6
    m2w64-crt-git:                  <span class=m>5</span>.0.0.4636.2595836-2
    m2w64-gcc:                      <span class=m>5</span>.3.0-6
    m2w64-gcc-ada:                  <span class=m>5</span>.3.0-6
    m2w64-gcc-fortran:              <span class=m>5</span>.3.0-6
    m2w64-gcc-libgfortran:          <span class=m>5</span>.3.0-6
    m2w64-gcc-libs:                 <span class=m>5</span>.3.0-7
    m2w64-gcc-libs-core:            <span class=m>5</span>.3.0-7
    m2w64-gcc-objc:                 <span class=m>5</span>.3.0-6
    m2w64-gmp:                      <span class=m>6</span>.1.0-2
    m2w64-headers-git:              <span class=m>5</span>.0.0.4636.c0ad18a-2
    m2w64-isl:                      <span class=m>0</span>.16.1-2
    m2w64-libiconv:                 <span class=m>1</span>.14-6
    m2w64-libmangle-git:            <span class=m>5</span>.0.0.4509.2e5a9a2-2
    m2w64-libwinpthread-git:        <span class=m>5</span>.0.0.4634.697f757-2
    m2w64-make:                     <span class=m>4</span>.1.2351.a80a8b8-2
    m2w64-mpc:                      <span class=m>1</span>.0.3-3
    m2w64-mpfr:                     <span class=m>3</span>.1.4-4
    m2w64-pkg-config:               <span class=m>0</span>.29.1-2
    m2w64-toolchain:                <span class=m>5</span>.3.0-7
    m2w64-tools-git:                <span class=m>5</span>.0.0.4592.90b8472-2
    m2w64-windows-default-manifest: <span class=m>6</span>.4-3
    m2w64-winpthreads-git:          <span class=m>5</span>.0.0.4634.697f757-2
    m2w64-zlib:                     <span class=m>1</span>.2.8-10
    markupsafe:                     <span class=m>0</span>.23-py36_2
    mistune:                        <span class=m>0</span>.7.4-py36_0
    mkl:                            <span class=m>2017</span>.0.3-0
    mkl-service:                    <span class=m>1</span>.1.2-py36_3
    msys2-conda-epoch:              <span class=m>20160418</span>-1
    nbconvert:                      <span class=m>5</span>.2.1-py36_0
    nbformat:                       <span class=m>4</span>.3.0-py36_0
    notebook:                       <span class=m>5</span>.0.0-py36_0
    numpy:                          <span class=m>1</span>.13.0-py36_0
    openssl:                        <span class=m>1</span>.0.2l-vc14_0        <span class=o>[</span>vc14<span class=o>]</span>
    pandocfilters:                  <span class=m>1</span>.4.1-py36_0
    path.py:                        <span class=m>10</span>.3.1-py36_0
    pickleshare:                    <span class=m>0</span>.7.4-py36_0
    pip:                            <span class=m>9</span>.0.1-py36_1
    prompt_toolkit:                 <span class=m>1</span>.0.14-py36_0
    pygments:                       <span class=m>2</span>.2.0-py36_0
    pyqt:                           <span class=m>5</span>.6.0-py36_2
    python:                         <span class=m>3</span>.6.1-2
    python-dateutil:                <span class=m>2</span>.6.0-py36_0
    pyzmq:                          <span class=m>16</span>.0.2-py36_0
    qt:                             <span class=m>5</span>.6.2-vc14_5         <span class=o>[</span>vc14<span class=o>]</span>
    qtconsole:                      <span class=m>4</span>.3.0-py36_0
    scipy:                          <span class=m>0</span>.19.1-np113py36_0
    setuptools:                     <span class=m>27</span>.2.0-py36_1
    simplegeneric:                  <span class=m>0</span>.8.1-py36_1
    sip:                            <span class=m>4</span>.18-py36_0
    six:                            <span class=m>1</span>.10.0-py36_0
    testpath:                       <span class=m>0</span>.3.1-py36_0
    tornado:                        <span class=m>4</span>.5.1-py36_0
    traitlets:                      <span class=m>4</span>.3.2-py36_0
    vs2015_runtime:                 <span class=m>14</span>.0.25420-0
    wcwidth:                        <span class=m>0</span>.1.7-py36_0
    wheel:                          <span class=m>0</span>.29.0-py36_0
    widgetsnbextension:             <span class=m>2</span>.0.0-py36_0
    zlib:                           <span class=m>1</span>.2.8-vc14_3         <span class=o>[</span>vc14<span class=o>]</span>

INFO menuinst_win32:__init__<span class=o>(</span><span class=m>182</span><span class=o>)</span>: Menu: name: <span class=s1>&#39;Anaconda${PY_VER} ${PLATFORM}&#39;</span>, prefix: <span class=s1>&#39;e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36&#39;</span>, env_name: <span class=s1>&#39;dlwin36&#39;</span>, mode: <span class=s1>&#39;None&#39;</span>, used_mode: <span class=s1>&#39;system&#39;</span>
INFO menuinst_win32:__init__<span class=o>(</span><span class=m>182</span><span class=o>)</span>: Menu: name: <span class=s1>&#39;Anaconda${PY_VER} ${PLATFORM}&#39;</span>, prefix: <span class=s1>&#39;e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36&#39;</span>, env_name: <span class=s1>&#39;dlwin36&#39;</span>, mode: <span class=s1>&#39;None&#39;</span>, used_mode: <span class=s1>&#39;system&#39;</span>
INFO menuinst_win32:__init__<span class=o>(</span><span class=m>182</span><span class=o>)</span>: Menu: name: <span class=s1>&#39;Anaconda${PY_VER} ${PLATFORM}&#39;</span>, prefix: <span class=s1>&#39;e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36&#39;</span>, env_name: <span class=s1>&#39;dlwin36&#39;</span>, mode: <span class=s1>&#39;None&#39;</span>, used_mode: <span class=s1>&#39;system&#39;</span>
<span class=c1>##</span>
<span class=c1>## 使用以下命令行激活环境:</span>
<span class=c1>## &gt; activate dlwin36</span>
<span class=c1>##</span>
<span class=c1>## 使用以下命令行关闭环境:</span>
<span class=c1>## &gt; deactivate dlwin36</span>
<span class=c1>##</span>
<span class=c1>## * for power-users using bash, you must source</span>
<span class=c1>##</span></code></pre></table></div></div><p>如上所示,使用 active dlwin36 命令激活这个新的环境.如果已经有了旧的 dlwin36 环境,可以先用 conda env remove -n dlwin36 命令删除.既然打算使用 GPU,为什么还要安装 CPU 优化的线性代数库如 MKL 呢?
在我们的设置中,大多数深度学习都是由 GPU 承担的,这并没错,但 CPU 也不是无所事事.基于图像的 Kaggle 竞赛一个重要部分是数据增强.如此看来,数据增强是通过转换原始训练样本(利用图像处理算子)获得额
外输入样本(即更多的训练图像)的过程.基本的转换比如下采样和均值归 0 的归一化也是必需的.如果你觉得这样太冒险,可以试试额外的预处理增强(噪声消除、直方图均化等等).当然也可以用 GPU 处理并把结果
保存到文件中.然而在实践过程中,这些计算通常都是在 CPU 上平行执行的,而 GPU 正忙于学习深度神经网络的权重,况且增强数据是用完即弃的.因此,我们强烈推荐安装 MKL,而 Theanos 用 BLAS 库更好.<h3 id=cuda-8-0-61-64-bit>CUDA 8.0.61 (64-bit)</h3><p>从<a href=https://developer.nvidia.com/cuda-downloads target=_blank>英伟达网站</a>下载 CUDA 8.0 (64-bit): <a href=https://developer.nvidia.com/cuda-downloads target=_blank>https://developer.nvidia.com/cuda-downloads</a><ul><li>选择合适的操作系统:</ul><p><img src=/img/post-content/deeplearning-on-windows/cuda8-downloads-win10a-2016-10.png alt><ul><li>下载安装包</ul><p><img src=/img/post-content/deeplearning-on-windows/cuda8-downloads-win10b-2017-07.png alt><ul><li>运行安装程序,安装在 <code>e:\toolkits.win\cuda-8.0.61</code>:</ul><p><img src=/img/post-content/deeplearning-on-windows/cuda8-install-part1-2016-10.png alt><p><img src=/img/post-content/deeplearning-on-windows/cuda8-install-part2-2016-10.png alt><p><img src=/img/post-content/deeplearning-on-windows/cuda8-install-part3-2017-07.png alt><p><img src=/img/post-content/deeplearning-on-windows/cuda8-install-part4-2016-10.png alt><p><img src=/img/post-content/deeplearning-on-windows/cuda8-install-part5-2016-10.png alt><p>完成安装后,安装包应该创建了一个名为<code>CUDA_PATH</code>的系统环境变量(sysenv variable),并且已经添加了<code>%CUDA_PATH%\bin</code>和<code>%CUDA_PATH%\libnvvp</code>到<code>PATH</code>中.检查是否真正添加了,若<code>CUDA</code>环境变量因为一些原因出错了,那么完成下面两个步骤:<ol><li>定义名为 <code>CUDA_PATH</code> 的系统环境变量的值为 <code>e:\toolkits.win\cuda-8.0.61</code><li>添加 <code>%CUDA_PATH%\bin</code> 和 <code>%CUDA_PATH%\libnvvp</code> 到 <code>PATH</code> 中</ol><h3 id=cudnn-v5-1-jan-20-2017-for-cuda-8-0>cuDNN v5.1 (Jan 20, 2017) for CUDA 8.0</h3><p>根据英伟达官网<code>「cuDNN 为标准的运算如前向和反向卷积、池化、归一化和激活层等提供高度调优的实现」</code>,它是为卷积神经网络和深度学习设计的一款加速方案.<ul><li>cuDNN 的下载地址: <a href=https://developer.nvidia.com/rdp/cudnn-download target=_blank>https://developer.nvidia.com/rdp/cudnn-download</a></ul><p>我们需要选择符合 CUDA 版本和 Window 10 编译器的 cuDNN 软件包,一般来说,cuDNN 5.1 可以支持 CUDA 8.0 和 Windows 10.<p><img src=/img/post-content/deeplearning-on-windows/cudnn-download-2017-07.jpg alt><p>下载的 ZIP 文件包含三个目录 <code>bin</code> 、 <code>include</code> 、<code>lib</code> ,抽取这三个的文件夹到 <code>%CUDA_PATH%</code> 中.<h3 id=安装-keras-2-0-5-和-theano0-9-0-与-libgpuarray>安装 Keras 2.0.5 和 Theano0.9.0 与 libgpuarray</h3><p>Why those specific versions? Why not just install the latest bleeding-edge/dev version of Keras and various backends (Tensorflow, CNTK or Theano)? Simply put, because it makes <a href=https://www.coursera.org/learn/reproducible-research target=_blank>reproducible research</a> harder. If your work colleagues or Kaggle teammates install the latest code from the dev branch at a different time than you did, you will most likely be running different code bases on your machines, increasing the odds that even though you&rsquo;re using the same input data (the same random seeds, etc.), you still end up with different results when you shouldn&rsquo;t. For this reason alone, we highly recommend only using point releases, the same one across machines, and always documenting which one you use if you can&rsquo;t just use a setup script.<p>运行以下命令安装<code>libgpuarray 0.6.2</code>,即<code>Theano 0.9.0</code>唯一的稳定版:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ conda install <span class=nv>pygpu</span><span class=o>==</span><span class=m>0</span>.6.2 nose
Fetching package metadata ...........
Solving package specifications: .

Package plan <span class=k>for</span> installation in environment e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36:

The following NEW packages will be INSTALLED:

    libgpuarray: <span class=m>0</span>.6.2-vc14_0 <span class=o>[</span>vc14<span class=o>]</span>
    nose:        <span class=m>1</span>.3.7-py36_1
    pygpu:       <span class=m>0</span>.6.2-py36_0

Proceed <span class=o>([</span>y<span class=o>]</span>/n<span class=o>)</span>? y</code></pre></table></div></div><blockquote><p>Note: As was reported by @bonifacio123 and @wpmarinho <a href=https://github.com/philferriere/dlwin/issues/40 target=_blank>here</a>, you may get a <code>ERROR (theano.gpuarray): Could not initialize pygpu, support disabled</code> error when using the flags <code>THEANO_FLAGS_GPU_DNN</code> with libgpuarray 0.6.2. If using cuDNN is crucial to your experiment, you can try using a more recent version of <code>libgpuarray</code> by running the following command instead: <code>conda install pygpu==0.6.9 nose</code>, keeping in mind that libgpuarray 0.6.2 is still the only stable version for Theano 0.9.0.</blockquote><p>输入以下命令安装<code>Keras</code>和<code>Theano</code>:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ pip install <span class=nv>keras</span><span class=o>==</span><span class=m>2</span>.0.5
Collecting <span class=nv>keras</span><span class=o>==</span><span class=m>2</span>.0.5
Requirement already satisfied: six in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from <span class=nv>keras</span><span class=o>==</span><span class=m>2</span>.0.5<span class=o>)</span>
Collecting pyyaml <span class=o>(</span>from <span class=nv>keras</span><span class=o>==</span><span class=m>2</span>.0.5<span class=o>)</span>
Collecting theano <span class=o>(</span>from <span class=nv>keras</span><span class=o>==</span><span class=m>2</span>.0.5<span class=o>)</span>
Requirement already satisfied: scipy&gt;<span class=o>=</span><span class=m>0</span>.14 in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from theano-&gt;keras<span class=o>==</span><span class=m>2</span>.0.5<span class=o>)</span>
Requirement already satisfied: numpy&gt;<span class=o>=</span><span class=m>1</span>.9.1 in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from theano-&gt;keras<span class=o>==</span><span class=m>2</span>.0.5<span class=o>)</span>
Installing collected packages: pyyaml, theano, keras
Successfully installed keras-2.0.5 pyyaml-3.12 theano-0.9.0</code></pre></table></div></div><h3 id=installing-the-cntk-2-0-backend>Installing the CNTK 2.0 backend</h3><p>安装 CNTK 2.0 后端
根据 CNTK 安装文档,我们可以使用以下 pip 命令行安装 CNTK <a href=https://docs.microsoft.com/en-us/cognitive-toolkit/setup-windows-python target=_blank>参考文档</a>:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ pip install https://cntk.ai/PythonWheel/GPU/cntk-2.0-cp36-cp36m-win_amd64.whl
Collecting <span class=nv>cntk</span><span class=o>==</span><span class=m>2</span>.0 from https://cntk.ai/PythonWheel/GPU/cntk-2.0-cp36-cp36m-win_amd64.whl
  Using cached https://cntk.ai/PythonWheel/GPU/cntk-2.0-cp36-cp36m-win_amd64.whl
Requirement already satisfied: numpy&gt;<span class=o>=</span><span class=m>1</span>.11 in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from <span class=nv>cntk</span><span class=o>==</span><span class=m>2</span>.0<span class=o>)</span>
Requirement already satisfied: scipy&gt;<span class=o>=</span><span class=m>0</span>.17 in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from <span class=nv>cntk</span><span class=o>==</span><span class=m>2</span>.0<span class=o>)</span>
Installing collected packages: cntk
Successfully installed cntk-2.0</code></pre></table></div></div><p>该安装将导致在 conda 环境目录下额外安装 <code>CUDA</code> 和 <code>cuDNN DLLs</code>:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>cd</span> E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36
<span class=o>(</span>dlwin36<span class=o>)</span> $ dir cu*.dll
 Volume in drive E is datasets
 Volume Serial Number is 1ED0-657B

 Directory of E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36

<span class=m>06</span>/30/2017  <span class=m>02</span>:47 PM        <span class=m>40</span>,744,896 cublas64_80.dll
<span class=m>06</span>/30/2017  <span class=m>02</span>:47 PM           <span class=m>366</span>,016 cudart64_80.dll
<span class=m>06</span>/30/2017  <span class=m>02</span>:47 PM        <span class=m>78</span>,389,760 cudnn64_5.dll
<span class=m>06</span>/30/2017  <span class=m>02</span>:47 PM        <span class=m>47</span>,985,208 curand64_80.dll
<span class=m>06</span>/30/2017  <span class=m>02</span>:47 PM        <span class=m>41</span>,780,280 cusparse64_80.dll
               <span class=m>5</span> File<span class=o>(</span>s<span class=o>)</span>    <span class=m>209</span>,266,160 bytes
               <span class=m>0</span> Dir<span class=o>(</span>s<span class=o>)</span>  <span class=m>400</span>,471,019,520 bytes free</code></pre></table></div></div><p>这个问题并不是因为浪费硬盘空间,而是安装的 <code>cuDNN</code> 版本和我们安装在 <code>c:\toolkits\cuda-8.0.61</code> 下的 <code>cuDNN</code> 版本不同,因为在 <code>conda</code> 环境目录下的 <code>DLL</code> 将首先加载,所以我们需要这些 <code>DLL</code> 移除出 <code>%PATH%</code> 目录:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ md discard <span class=p>&amp;</span> move cu*.dll discard
E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\c</span>ublas64_80.dll
E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\c</span>udart64_80.dll
E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\c</span>udnn64_5.dll
E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\c</span>urand64_80.dll
E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\c</span>usparse64_80.dll
        <span class=m>5</span> file<span class=o>(</span>s<span class=o>)</span> moved.</code></pre></table></div></div><h3 id=安装-tensorflow-gpu-1-2-0-后端>安装 TensorFlow-GPU 1.2.0 后端</h3><p>运行以下命令行使用 <code>pip</code> 安装 <code>TensorFlow</code>:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ pip install tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0
Collecting tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0
  Using cached tensorflow_gpu-1.2.0-cp36-cp36m-win_amd64.whl
Requirement already satisfied: <span class=nv>bleach</span><span class=o>==</span><span class=m>1</span>.5.0 in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
Requirement already satisfied: numpy&gt;<span class=o>=</span><span class=m>1</span>.11.0 in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
Collecting <span class=nv>markdown</span><span class=o>==</span><span class=m>2</span>.2.0 <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
Requirement already satisfied: wheel&gt;<span class=o>=</span><span class=m>0</span>.26 in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
Collecting protobuf&gt;<span class=o>=</span><span class=m>3</span>.2.0 <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
Collecting backports.weakref<span class=o>==</span><span class=m>1</span>.0rc1 <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
  Using cached backports.weakref-1.0rc1-py3-none-any.whl
Collecting <span class=nv>html5lib</span><span class=o>==</span><span class=m>0</span>.9999999 <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
Collecting werkzeug&gt;<span class=o>=</span><span class=m>0</span>.11.10 <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
  Using cached Werkzeug-0.12.2-py2.py3-none-any.whl
Requirement already satisfied: six&gt;<span class=o>=</span><span class=m>1</span>.10.0 in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages <span class=o>(</span>from tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
Requirement already satisfied: setuptools in e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages<span class=se>\s</span>etuptools-27.2.0-py3.6.egg <span class=o>(</span>from protobuf&gt;<span class=o>=</span><span class=m>3</span>.2.0-&gt;tensorflow-gpu<span class=o>==</span><span class=m>1</span>.2.0<span class=o>)</span>
Installing collected packages: markdown, protobuf, backports.weakref, html5lib, werkzeug, tensorflow-gpu
  Found existing installation: html5lib <span class=m>0</span>.999
    DEPRECATION: Uninstalling a distutils installed project <span class=o>(</span>html5lib<span class=o>)</span> has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.
    Uninstalling html5lib-0.999:
      Successfully uninstalled html5lib-0.999
Successfully installed backports.weakref-1.0rc1 html5lib-0.9999999 markdown-2.2.0 protobuf-3.3.0 tensorflow-gpu-1.2.0 werkzeug-0.12.2</code></pre></table></div></div><h3 id=使用-conda-检查安装的软件包>使用 conda 检查安装的软件包</h3><p>完成以上安装和配置后,我们应该在 <code>dlwin36</code> conda 环境中看到以下软件包列表:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span><span class=lnt>91
</span><span class=lnt>92
</span><span class=lnt>93
</span><span class=lnt>94
</span><span class=lnt>95
</span><span class=lnt>96
</span><span class=lnt>97
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ conda list
<span class=c1>## packages in environment at e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36:</span>
<span class=c1>##</span>
backports.weakref         <span class=m>1</span>.0rc1                    &lt;pip&gt;
bleach                    <span class=m>1</span>.5.0                    py36_0
cntk                      <span class=m>2</span>.0                       &lt;pip&gt;
colorama                  <span class=m>0</span>.3.9                    py36_0
decorator                 <span class=m>4</span>.0.11                   py36_0
entrypoints               <span class=m>0</span>.2.2                    py36_1
html5lib                  <span class=m>0</span>.999                    py36_0
html5lib                  <span class=m>0</span>.9999999                 &lt;pip&gt;
icu                       <span class=m>57</span>.1                     vc14_0  <span class=o>[</span>vc14<span class=o>]</span>
ipykernel                 <span class=m>4</span>.6.1                    py36_0
ipython                   <span class=m>6</span>.1.0                    py36_0
ipython_genutils          <span class=m>0</span>.2.0                    py36_0
ipywidgets                <span class=m>6</span>.0.0                    py36_0
jedi                      <span class=m>0</span>.10.2                   py36_2
jinja2                    <span class=m>2</span>.9.6                    py36_0
jpeg                      9b                       vc14_0  <span class=o>[</span>vc14<span class=o>]</span>
jsonschema                <span class=m>2</span>.6.0                    py36_0
jupyter                   <span class=m>1</span>.0.0                    py36_3
jupyter_client            <span class=m>5</span>.1.0                    py36_0
jupyter_console           <span class=m>5</span>.1.0                    py36_0
jupyter_core              <span class=m>4</span>.3.0                    py36_0
Keras                     <span class=m>2</span>.0.5                     &lt;pip&gt;
libgpuarray               <span class=m>0</span>.6.2                    vc14_0  <span class=o>[</span>vc14<span class=o>]</span>
libpng                    <span class=m>1</span>.6.27                   vc14_0  <span class=o>[</span>vc14<span class=o>]</span>
libpython                 <span class=m>2</span>.0                      py36_0
m2w64-binutils            <span class=m>2</span>.25.1                        <span class=m>5</span>
m2w64-bzip2               <span class=m>1</span>.0.6                         <span class=m>6</span>
m2w64-crt-git             <span class=m>5</span>.0.0.4636.2595836               <span class=m>2</span>
m2w64-gcc                 <span class=m>5</span>.3.0                         <span class=m>6</span>
m2w64-gcc-ada             <span class=m>5</span>.3.0                         <span class=m>6</span>
m2w64-gcc-fortran         <span class=m>5</span>.3.0                         <span class=m>6</span>
m2w64-gcc-libgfortran     <span class=m>5</span>.3.0                         <span class=m>6</span>
m2w64-gcc-libs            <span class=m>5</span>.3.0                         <span class=m>7</span>
m2w64-gcc-libs-core       <span class=m>5</span>.3.0                         <span class=m>7</span>
m2w64-gcc-objc            <span class=m>5</span>.3.0                         <span class=m>6</span>
m2w64-gmp                 <span class=m>6</span>.1.0                         <span class=m>2</span>
m2w64-headers-git         <span class=m>5</span>.0.0.4636.c0ad18a               <span class=m>2</span>
m2w64-isl                 <span class=m>0</span>.16.1                        <span class=m>2</span>
m2w64-libiconv            <span class=m>1</span>.14                          <span class=m>6</span>
m2w64-libmangle-git       <span class=m>5</span>.0.0.4509.2e5a9a2               <span class=m>2</span>
m2w64-libwinpthread-git   <span class=m>5</span>.0.0.4634.697f757               <span class=m>2</span>
m2w64-make                <span class=m>4</span>.1.2351.a80a8b8               <span class=m>2</span>
m2w64-mpc                 <span class=m>1</span>.0.3                         <span class=m>3</span>
m2w64-mpfr                <span class=m>3</span>.1.4                         <span class=m>4</span>
m2w64-pkg-config          <span class=m>0</span>.29.1                        <span class=m>2</span>
m2w64-toolchain           <span class=m>5</span>.3.0                         <span class=m>7</span>
m2w64-tools-git           <span class=m>5</span>.0.0.4592.90b8472               <span class=m>2</span>
m2w64-windows-default-manifest <span class=m>6</span>.4                           <span class=m>3</span>
m2w64-winpthreads-git     <span class=m>5</span>.0.0.4634.697f757               <span class=m>2</span>
m2w64-zlib                <span class=m>1</span>.2.8                        <span class=m>10</span>
mako                      <span class=m>1</span>.0.6                    py36_0
Markdown                  <span class=m>2</span>.2.0                     &lt;pip&gt;
markupsafe                <span class=m>0</span>.23                     py36_2
mistune                   <span class=m>0</span>.7.4                    py36_0
mkl                       <span class=m>2017</span>.0.3                      <span class=m>0</span>
mkl-service               <span class=m>1</span>.1.2                    py36_3
msys2-conda-epoch         <span class=m>20160418</span>                      <span class=m>1</span>
nbconvert                 <span class=m>5</span>.2.1                    py36_0
nbformat                  <span class=m>4</span>.3.0                    py36_0
nose                      <span class=m>1</span>.3.7                    py36_1
notebook                  <span class=m>5</span>.0.0                    py36_0
numpy                     <span class=m>1</span>.13.0                   py36_0
openssl                   <span class=m>1</span>.0.2l                   vc14_0  <span class=o>[</span>vc14<span class=o>]</span>
pandocfilters             <span class=m>1</span>.4.1                    py36_0
path.py                   <span class=m>10</span>.3.1                   py36_0
pickleshare               <span class=m>0</span>.7.4                    py36_0
pip                       <span class=m>9</span>.0.1                    py36_1
prompt_toolkit            <span class=m>1</span>.0.14                   py36_0
protobuf                  <span class=m>3</span>.3.0                     &lt;pip&gt;
pygments                  <span class=m>2</span>.2.0                    py36_0
pygpu                     <span class=m>0</span>.6.2                    py36_0
pyqt                      <span class=m>5</span>.6.0                    py36_2
python                    <span class=m>3</span>.6.1                         <span class=m>2</span>
python-dateutil           <span class=m>2</span>.6.0                    py36_0
PyYAML                    <span class=m>3</span>.12                      &lt;pip&gt;
pyzmq                     <span class=m>16</span>.0.2                   py36_0
qt                        <span class=m>5</span>.6.2                    vc14_5  <span class=o>[</span>vc14<span class=o>]</span>
qtconsole                 <span class=m>4</span>.3.0                    py36_0
scipy                     <span class=m>0</span>.19.1              np113py36_0
setuptools                <span class=m>27</span>.2.0                   py36_1
simplegeneric             <span class=m>0</span>.8.1                    py36_1
sip                       <span class=m>4</span>.18                     py36_0
six                       <span class=m>1</span>.10.0                   py36_0
tensorflow-gpu            <span class=m>1</span>.2.0                     &lt;pip&gt;
testpath                  <span class=m>0</span>.3.1                    py36_0
Theano                    <span class=m>0</span>.9.0                     &lt;pip&gt;
tornado                   <span class=m>4</span>.5.1                    py36_0
traitlets                 <span class=m>4</span>.3.2                    py36_0
vs2015_runtime            <span class=m>14</span>.0.25420                    <span class=m>0</span>
wcwidth                   <span class=m>0</span>.1.7                    py36_0
Werkzeug                  <span class=m>0</span>.12.2                    &lt;pip&gt;
wheel                     <span class=m>0</span>.29.0                   py36_0
widgetsnbextension        <span class=m>2</span>.0.0                    py36_0
zlib                      <span class=m>1</span>.2.8                    vc14_3  <span class=o>[</span>vc14<span class=o>]</span></code></pre></table></div></div><p>为了快速检查上述三个后端安装的效果,依次运行一下命令行分别检查 <code>Theano</code>、<code>TensorFlow</code> 和 <code>CNTK</code> 导入情况:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ python -c <span class=s2>&#34;import theano; print(&#39;theano: %s, %s&#39; % (theano.__version__, theano.__file__))&#34;</span>
theano: <span class=m>0</span>.9.0, E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages<span class=se>\t</span>heano<span class=se>\_</span>_init__.py
<span class=o>(</span>dlwin36<span class=o>)</span> $ python -c <span class=s2>&#34;import pygpu; print(&#39;pygpu: %s, %s&#39; % (pygpu.__version__, pygpu.__file__))&#34;</span>
pygpu: <span class=m>0</span>.6.2, e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages<span class=se>\p</span>ygpu<span class=se>\_</span>_init__.py
<span class=o>(</span>dlwin36<span class=o>)</span> $ python -c <span class=s2>&#34;import tensorflow; print(&#39;tensorflow: %s, %s&#39; % (tensorflow.__version__, tensorflow.__file__))&#34;</span>
tensorflow: <span class=m>1</span>.2.0, E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages<span class=se>\t</span>ensorflow<span class=se>\_</span>_init__.py
<span class=o>(</span>dlwin36<span class=o>)</span> $ python -c <span class=s2>&#34;import cntk; print(&#39;cntk: %s, %s&#39; % (cntk.__version__, cntk.__file__))&#34;</span>
cntk: <span class=m>2</span>.0, E:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages<span class=se>\c</span>ntk<span class=se>\_</span>_init__.py</code></pre></table></div></div><h3 id=验证-theano-的安装>验证 Theano 的安装</h3><p>因为 <code>Theano</code> 是安装 <code>Keras</code> 时自动安装的,为了快速地在 <code>CPU 模式</code>、<code>GPU 模式</code>和<code>带cuDNN的 GPU 模式</code>之间转换,我们需要创建以下三个系统环境变量(sysenv variable):<ul><li>系统环境变量 <code>THEANO_FLAGS_CPU</code> 的值定义为: <code>floatX=float32,device=cpu</code><li><p>系统环境变量 <code>THEANO_FLAGS_GPU</code> 的值定义为:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><span class=lnt>1
</span></pre><td class=lntd><pre class=chroma>floatX=float32,device=cuda0,dnn.enabled=False,gpuarray.preallocate=0.8</pre></table></div></div><li><p>系统环境变量 <code>THEANO_FLAGS_GPU_DNN</code> 的值定义为:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><span class=lnt>1
</span></pre><td class=lntd><pre class=chroma>floatX=float32,device=cuda0,optimizer_including=cudnn,gpuarray.preallocate=0.8,dnn.conv.algo_bwd_filter=deterministic,dnn.conv.algo_bwd_data=deterministic,dnn.include_path=e:/toolkits.win/cuda-8.0.61/include,dnn.library_path=e:/toolkits.win/cuda-8.0.61/lib/x64</pre></table></div></div></ul><p>现在,我们能直接使用 <code>THEANO_FLAGS_CPU</code>、<code>THEANO_FLAGS_GPU</code> 或 <code>THEANO_FLAGS_GPU_DNN</code> 直接设置 <code>Theano</code> 使用 <code>CPU</code>、<code>GPU</code> 还是 <code>GPU+cuDNN</code>.我们可以使用以下命令行验证这些变量是否成功加入环境中:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>KERAS_BACKEND</span><span class=o>=</span>theano
<span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=p>|</span> findstr /i theano
<span class=nv>KERAS_BACKEND</span><span class=o>=</span>theano
<span class=nv>THEANO_FLAGS</span><span class=o>=</span><span class=nv>floatX</span><span class=o>=</span>float32,device<span class=o>=</span>cuda0,optimizer_including<span class=o>=</span>cudnn,gpuarray.preallocate<span class=o>=</span><span class=m>0</span>.8,dnn.conv.algo_bwd_filter<span class=o>=</span>deterministic,dnn.conv.algo_bwd_data<span class=o>=</span>deterministic,dnn.include_path<span class=o>=</span>e:/toolkits.win/cuda-8.0.61/include,dnn.library_path<span class=o>=</span>e:/toolkits.win/cuda-8.0.61/lib/x64
<span class=nv>THEANO_FLAGS_CPU</span><span class=o>=</span><span class=nv>floatX</span><span class=o>=</span>float32,device<span class=o>=</span>cpu
<span class=nv>THEANO_FLAGS_GPU</span><span class=o>=</span><span class=nv>floatX</span><span class=o>=</span>float32,device<span class=o>=</span>cuda0,dnn.enabled<span class=o>=</span>False,gpuarray.preallocate<span class=o>=</span><span class=m>0</span>.8
<span class=nv>THEANO_FLAGS_GPU_DNN</span><span class=o>=</span><span class=nv>floatX</span><span class=o>=</span>float32,device<span class=o>=</span>cuda0,optimizer_including<span class=o>=</span>cudnn,gpuarray.preallocate<span class=o>=</span><span class=m>0</span>.8,dnn.conv.algo_bwd_filter<span class=o>=</span>deterministic,dnn.conv.algo_bwd_data<span class=o>=</span>deterministic,dnn.include_path<span class=o>=</span>e:/toolkits.win/cuda-8.0.61/include,dnn.library_path<span class=o>=</span>e:/toolkits.win/cuda-8.0.61/lib/x64</code></pre></table></div></div><blockquote><p>Note: For information about the GPU flags above, please refer to the official Theano documentation <a href=http://deeplearning.net/software/theano/tutorial/using_gpu.html target=_blank>here</a></blockquote><p>We can now run the following program from the Theano documentation to compare the performance of the GPU install vs using Theano in CPU-mode. Save the code to a file named <code>cpu_gpu_test.py</code> in the current directory (or download it from this <a href=https://github.com/philferriere/dlwin target=_blank>GitHub repo</a>):<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=kn>from</span> <span class=nn>theano</span> <span class=kn>import</span> <span class=n>function</span><span class=p>,</span> <span class=n>config</span><span class=p>,</span> <span class=n>shared</span><span class=p>,</span> <span class=n>tensor</span>
<span class=kn>import</span> <span class=nn>numpy</span>
<span class=kn>import</span> <span class=nn>time</span>

<span class=n>vlen</span> <span class=o>=</span> <span class=mi>10</span> <span class=o>*</span> <span class=mi>30</span> <span class=o>*</span> <span class=mi>768</span>  <span class=c1>## 10 x ##cores x ## threads per core</span>
<span class=n>iters</span> <span class=o>=</span> <span class=mi>1000</span>

<span class=n>rng</span> <span class=o>=</span> <span class=n>numpy</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>RandomState</span><span class=p>(</span><span class=mi>22</span><span class=p>)</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>shared</span><span class=p>(</span><span class=n>numpy</span><span class=o>.</span><span class=n>asarray</span><span class=p>(</span><span class=n>rng</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>vlen</span><span class=p>),</span> <span class=n>config</span><span class=o>.</span><span class=n>floatX</span><span class=p>))</span>
<span class=n>f</span> <span class=o>=</span> <span class=n>function</span><span class=p>([],</span> <span class=n>tensor</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
<span class=k>print</span><span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>maker</span><span class=o>.</span><span class=n>fgraph</span><span class=o>.</span><span class=n>toposort</span><span class=p>())</span>
<span class=n>t0</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>iters</span><span class=p>):</span>
    <span class=n>r</span> <span class=o>=</span> <span class=n>f</span><span class=p>()</span>
<span class=n>t1</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;Looping </span><span class=si>%d</span><span class=s2> times took </span><span class=si>%f</span><span class=s2> seconds&#34;</span> <span class=o>%</span> <span class=p>(</span><span class=n>iters</span><span class=p>,</span> <span class=n>t1</span> <span class=o>-</span> <span class=n>t0</span><span class=p>))</span>
<span class=k>print</span><span class=p>(</span><span class=s2>&#34;Result is </span><span class=si>%s</span><span class=s2>&#34;</span> <span class=o>%</span> <span class=p>(</span><span class=n>r</span><span class=p>,))</span>
<span class=k>if</span> <span class=n>numpy</span><span class=o>.</span><span class=nb>any</span><span class=p>([</span><span class=nb>isinstance</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>op</span><span class=p>,</span> <span class=n>tensor</span><span class=o>.</span><span class=n>Elemwise</span><span class=p>)</span> <span class=ow>and</span>
              <span class=p>(</span><span class=s1>&#39;Gpu&#39;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=nb>type</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>op</span><span class=p>)</span><span class=o>.</span><span class=vm>__name__</span><span class=p>)</span>
              <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>f</span><span class=o>.</span><span class=n>maker</span><span class=o>.</span><span class=n>fgraph</span><span class=o>.</span><span class=n>toposort</span><span class=p>()]):</span>
    <span class=k>print</span><span class=p>(</span><span class=s1>&#39;Used the cpu&#39;</span><span class=p>)</span>
<span class=k>else</span><span class=p>:</span>
    <span class=k>print</span><span class=p>(</span><span class=s1>&#39;Used the gpu&#39;</span><span class=p>)</span></code></pre></table></div></div><p>First, let&rsquo;s see what kind of results we get running Theano in CPU mode:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>THEANO_FLAGS</span><span class=o>=</span>%THEANO_FLAGS_CPU%
<span class=o>(</span>dlwin36<span class=o>)</span> $ python cpu_gpu_test.py
<span class=o>[</span>Elemwise<span class=o>{</span>exp,no_inplace<span class=o>}(</span>&lt;TensorType<span class=o>(</span>float32, vector<span class=o>)</span>&gt;<span class=o>)]</span>
Looping <span class=m>1000</span> <span class=nb>times</span> took <span class=m>16</span>.037982 seconds
Result is <span class=o>[</span> <span class=m>1</span>.23178029  <span class=m>1</span>.61879337  <span class=m>1</span>.52278066 ...,  <span class=m>2</span>.20771813  <span class=m>2</span>.29967761
  <span class=m>1</span>.62323284<span class=o>]</span>
Used the cpu</code></pre></table></div></div><blockquote><p>Note: If you get a failure of the kind <code>NameError: global name 'CVM' is not defined</code>, it may be because, like us, you&rsquo;ve messed with the value of <code>THEANO_FLAGS_CPU</code> and switched back and forth between <code>floatX=float32</code> and <code>floatX=float64</code> several times. Cleaning your <code>C:\Users\username\AppData\Local\Theano</code> directory (replace username with your login name) will fix the problem (See <a href=https://groups.google.com/forum/##!msg/theano-users/JoTu61_MTLk/4ZzsVyaOf2kJ target=_blank>here</a>, for reference)</blockquote><p>Next, let&rsquo;s run the same program on the GPU:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>THEANO_FLAGS</span><span class=o>=</span>%THEANO_FLAGS_GPU%
<span class=o>(</span>dlwin36<span class=o>)</span> $ python cpu_gpu_test.py
Can not use cuDNN on context None: Disabled by dnn.enabled flag
Preallocating <span class=m>9830</span>/12288 Mb <span class=o>(</span><span class=m>0</span>.800000<span class=o>)</span> on cuda0
Mapped name None to device cuda0: GeForce GTX TITAN X <span class=o>(</span><span class=m>0000</span>:03:00.0<span class=o>)</span>
<span class=o>[</span>GpuElemwise<span class=o>{</span>exp,no_inplace<span class=o>}(</span>&lt;GpuArrayType&lt;None&gt;<span class=o>(</span>float32, <span class=o>(</span>False,<span class=o>))</span>&gt;<span class=o>)</span>, HostFromGpu<span class=o>(</span>gpuarray<span class=o>)(</span>GpuElemwise<span class=o>{</span>exp,no_inplace<span class=o>}</span>.0<span class=o>)]</span>
Looping <span class=m>1000</span> <span class=nb>times</span> took <span class=m>0</span>.293377 seconds
Result is <span class=o>[</span> <span class=m>1</span>.23178029  <span class=m>1</span>.61879349  <span class=m>1</span>.52278066 ...,  <span class=m>2</span>.20771813  <span class=m>2</span>.29967761
  <span class=m>1</span>.62323296<span class=o>]</span>
Used the gpu</code></pre></table></div></div><blockquote><p>Note: If you get a <code>c:\program files (x86)\microsoft visual studio 14.0\vc\include\crtdefs.h(10): fatal error C1083: Cannot open include file: 'corecrt.h': No such file or directory</code> with the above, please see the Reference Note at the end of the <code>Visual Studio 2015 Community Edition Update 3</code> section.</blockquote><p>Almost <strong>a 55:1 improvement</strong>!. Finally, let&rsquo;s make sure we can also use Theano in GPU mode with cuDNN:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>THEANO_FLAGS</span><span class=o>=</span>%THEANO_FLAGS_GPU_DNN%
<span class=o>(</span>dlwin36<span class=o>)</span> $ python cpu_gpu_test.py
Using cuDNN version <span class=m>5110</span> on context None
Preallocating <span class=m>9830</span>/12288 Mb <span class=o>(</span><span class=m>0</span>.800000<span class=o>)</span> on cuda0
Mapped name None to device cuda0: GeForce GTX TITAN X <span class=o>(</span><span class=m>0000</span>:03:00.0<span class=o>)</span>
<span class=o>[</span>GpuElemwise<span class=o>{</span>exp,no_inplace<span class=o>}(</span>&lt;GpuArrayType&lt;None&gt;<span class=o>(</span>float32, <span class=o>(</span>False,<span class=o>))</span>&gt;<span class=o>)</span>, HostFromGpu<span class=o>(</span>gpuarray<span class=o>)(</span>GpuElemwise<span class=o>{</span>exp,no_inplace<span class=o>}</span>.0<span class=o>)]</span>
Looping <span class=m>1000</span> <span class=nb>times</span> took <span class=m>0</span>.269696 seconds
Result is <span class=o>[</span> <span class=m>1</span>.23178029  <span class=m>1</span>.61879349  <span class=m>1</span>.52278066 ...,  <span class=m>2</span>.20771813  <span class=m>2</span>.29967761
  <span class=m>1</span>.62323296<span class=o>]</span>
Used the gpu</code></pre></table></div></div><blockquote><p>Note: If you get a <code>cuDNN not available</code> message after this, try cleaning your <code>%USERPROFILE%\AppData\Local\Theano</code> directory. If you get an error similar to <code>cudnn error: Mixed dnn version. The header is from one version, but we link with a different version (5010, 5005)</code>, try cuDNN v5.0 instead of cuDNN v5.1. Windows will sometimes also helpfully block foreign <code>.dll</code> files from running on your computer. If that is the case, right click and unblock the files to allow them to be used.</blockquote><h3 id=检查系统环境变量>检查系统环境变量</h3><p>现在,不论 <code>dlwin36</code> conda 环境什么时候激活,<code>PATH</code> 环境变量应该需要看起来如下面列表一样:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash>e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\L</span>ibrary<span class=se>\m</span>ingw-w64<span class=se>\b</span>in<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\L</span>ibrary<span class=se>\u</span>sr<span class=se>\b</span>in<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\L</span>ibrary<span class=se>\b</span>in<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\S</span>cripts<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\S</span>cripts<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\L</span>ibrary<span class=se>\b</span>in<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\c</span>uda-8.0.61<span class=se>\b</span>in<span class=p>;</span>
e:<span class=se>\t</span>oolkits.win<span class=se>\c</span>uda-8.0.61<span class=se>\l</span>ibnvvp<span class=p>;</span>
C:<span class=se>\P</span>rogramData<span class=se>\O</span>racle<span class=se>\J</span>ava<span class=se>\j</span>avapath<span class=p>;</span>
C:<span class=se>\W</span>INDOWS<span class=se>\s</span>ystem32<span class=p>;</span>
C:<span class=se>\W</span>INDOWS<span class=p>;</span>C:<span class=se>\W</span>INDOWS<span class=se>\S</span>ystem32<span class=se>\W</span>bem<span class=p>;</span>
C:<span class=se>\W</span>INDOWS<span class=se>\S</span>ystem32<span class=se>\W</span>indowsPowerShell<span class=se>\v</span><span class=m>1</span>.0<span class=se>\;</span>
C:<span class=se>\P</span>rogram Files <span class=o>(</span>x86<span class=o>)</span><span class=se>\N</span>VIDIA Corporation<span class=se>\P</span>hysX<span class=se>\C</span>ommon<span class=p>;</span>
C:<span class=se>\P</span>rogram Files <span class=o>(</span>x86<span class=o>)</span><span class=se>\M</span>icrosoft Visual Studio <span class=m>14</span>.0<span class=se>\V</span>C<span class=se>\b</span>in<span class=p>;</span>
C:<span class=se>\P</span>rogram Files<span class=se>\G</span>it<span class=se>\c</span>md<span class=p>;</span>
C:<span class=se>\P</span>rogram Files<span class=se>\G</span>it<span class=se>\m</span>ingw64<span class=se>\b</span>in<span class=p>;</span>
C:<span class=se>\P</span>rogram Files<span class=se>\G</span>it<span class=se>\u</span>sr<span class=se>\b</span>in<span class=p>;</span>
C:<span class=se>\P</span>rogram Files <span class=o>(</span>x86<span class=o>)</span><span class=se>\W</span>indows Kits<span class=se>\1</span><span class=m>0</span><span class=se>\W</span>indows Performance Toolkit<span class=se>\;</span>
...</code></pre></table></div></div><h3 id=使用-keras-验证-gpu-cudnn-的安装>使用 Keras 验证 GPU+cuDNN 的安装</h3><p>我们可以使用 <code>Keras</code> 在 <code>MNIST</code> 数据集上训练简单的卷积神经网络(<a href=https://en.wikipedia.org/wiki/Convolutional_neural_network target=_blank>convolutional neural network</a>)来验证 GPU 的 cuDNN 是否正确安装,该文件名为 <code>mnist_cnn.py</code>,其可以在 <code>Keras</code> <a href=https://github.com/fchollet/keras/blob/2.0.5/examples/mnist_cnn.py target=_blank>案例</a>中找到.该卷积神经网络的代码如下:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span></code></pre><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=s1>&#39;&#39;&#39;Trains a simple convnet on the MNIST dataset.
</span><span class=s1>
</span><span class=s1>Gets to 99.25% test accuracy after 12 epochs
</span><span class=s1>(there is still a lot of margin for parameter tuning).
</span><span class=s1>16 seconds per epoch on a GRID K520 GPU.
</span><span class=s1>&#39;&#39;&#39;</span>

<span class=kn>from</span> <span class=nn>__future__</span> <span class=kn>import</span> <span class=n>print_function</span>
<span class=kn>import</span> <span class=nn>keras</span>
<span class=kn>from</span> <span class=nn>keras.datasets</span> <span class=kn>import</span> <span class=n>mnist</span>
<span class=kn>from</span> <span class=nn>keras.models</span> <span class=kn>import</span> <span class=n>Sequential</span>
<span class=kn>from</span> <span class=nn>keras.layers</span> <span class=kn>import</span> <span class=n>Dense</span><span class=p>,</span> <span class=n>Dropout</span><span class=p>,</span> <span class=n>Flatten</span>
<span class=kn>from</span> <span class=nn>keras.layers</span> <span class=kn>import</span> <span class=n>Conv2D</span><span class=p>,</span> <span class=n>MaxPooling2D</span>
<span class=kn>from</span> <span class=nn>keras</span> <span class=kn>import</span> <span class=n>backend</span> <span class=k>as</span> <span class=n>K</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>128</span>
<span class=n>num_classes</span> <span class=o>=</span> <span class=mi>10</span>
<span class=n>epochs</span> <span class=o>=</span> <span class=mi>12</span>

<span class=c1>## input image dimensions</span>
<span class=n>img_rows</span><span class=p>,</span> <span class=n>img_cols</span> <span class=o>=</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>28</span>

<span class=c1>## the data, shuffled and split between train and test sets</span>
<span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>),</span> <span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span> <span class=o>=</span> <span class=n>mnist</span><span class=o>.</span><span class=n>load_data</span><span class=p>()</span>

<span class=k>if</span> <span class=n>K</span><span class=o>.</span><span class=n>image_data_format</span><span class=p>()</span> <span class=o>==</span> <span class=s1>&#39;channels_first&#39;</span><span class=p>:</span>
    <span class=n>x_train</span> <span class=o>=</span> <span class=n>x_train</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=mi>1</span><span class=p>,</span> <span class=n>img_rows</span><span class=p>,</span> <span class=n>img_cols</span><span class=p>)</span>
    <span class=n>x_test</span> <span class=o>=</span> <span class=n>x_test</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>x_test</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=mi>1</span><span class=p>,</span> <span class=n>img_rows</span><span class=p>,</span> <span class=n>img_cols</span><span class=p>)</span>
    <span class=n>input_shape</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>img_rows</span><span class=p>,</span> <span class=n>img_cols</span><span class=p>)</span>
<span class=k>else</span><span class=p>:</span>
    <span class=n>x_train</span> <span class=o>=</span> <span class=n>x_train</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>img_rows</span><span class=p>,</span> <span class=n>img_cols</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
    <span class=n>x_test</span> <span class=o>=</span> <span class=n>x_test</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>x_test</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>img_rows</span><span class=p>,</span> <span class=n>img_cols</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
    <span class=n>input_shape</span> <span class=o>=</span> <span class=p>(</span><span class=n>img_rows</span><span class=p>,</span> <span class=n>img_cols</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

<span class=n>x_train</span> <span class=o>=</span> <span class=n>x_train</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span>
<span class=n>x_test</span> <span class=o>=</span> <span class=n>x_test</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span>
<span class=n>x_train</span> <span class=o>/=</span> <span class=mi>255</span>
<span class=n>x_test</span> <span class=o>/=</span> <span class=mi>255</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;x_train shape:&#39;</span><span class=p>,</span> <span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=s1>&#39;train samples&#39;</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=n>x_test</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=s1>&#39;test samples&#39;</span><span class=p>)</span>

<span class=c1>## convert class vectors to binary class matrices</span>
<span class=n>y_train</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>to_categorical</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
<span class=n>y_test</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>to_categorical</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>()</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span>
                 <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span>
                 <span class=n>input_shape</span><span class=o>=</span><span class=n>input_shape</span><span class=p>))</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>),</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>))</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Flatten</span><span class=p>())</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>))</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>))</span>
<span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=n>num_classes</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;softmax&#39;</span><span class=p>))</span>

<span class=n>model</span><span class=o>.</span><span class=nb>compile</span><span class=p>(</span><span class=n>loss</span><span class=o>=</span><span class=n>keras</span><span class=o>.</span><span class=n>losses</span><span class=o>.</span><span class=n>categorical_crossentropy</span><span class=p>,</span>
              <span class=n>optimizer</span><span class=o>=</span><span class=n>keras</span><span class=o>.</span><span class=n>optimizers</span><span class=o>.</span><span class=n>Adadelta</span><span class=p>(),</span>
              <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>])</span>

<span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span>
          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span>
          <span class=n>epochs</span><span class=o>=</span><span class=n>epochs</span><span class=p>,</span>
          <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
          <span class=n>validation_data</span><span class=o>=</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
<span class=n>score</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;Test loss:&#39;</span><span class=p>,</span> <span class=n>score</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
<span class=k>print</span><span class=p>(</span><span class=s1>&#39;Test accuracy:&#39;</span><span class=p>,</span> <span class=n>score</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span></code></pre></table></div></div><h4 id=1-使用带-theano-后端的-keras>1.使用带 Theano 后端的 Keras</h4><p>J为了有一个能进行对比的基线模型,首先我们使用 Theano 后端和 CPU 训练简单的卷积神经网络:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>KERAS_BACKEND</span><span class=o>=</span>theano
<span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>THEANO_FLAGS</span><span class=o>=</span>%THEANO_FLAGS_CPU%
<span class=o>(</span>dlwin36<span class=o>)</span> $ python mnist_cnn.py
Using Theano backend.
x_train shape: <span class=o>(</span><span class=m>60000</span>, <span class=m>28</span>, <span class=m>28</span>, <span class=m>1</span><span class=o>)</span>
<span class=m>60000</span> train samples
<span class=m>10000</span> <span class=nb>test</span> samples
Train on <span class=m>60000</span> samples, validate on <span class=m>10000</span> samples
Epoch <span class=m>1</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 233s - loss: <span class=m>0</span>.3344 - acc: <span class=m>0</span>.8972 - val_loss: <span class=m>0</span>.0743 - val_acc: <span class=m>0</span>.9777
Epoch <span class=m>2</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 234s - loss: <span class=m>0</span>.1106 - acc: <span class=m>0</span>.9674 - val_loss: <span class=m>0</span>.0504 - val_acc: <span class=m>0</span>.9837
Epoch <span class=m>3</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 237s - loss: <span class=m>0</span>.0865 - acc: <span class=m>0</span>.9741 - val_loss: <span class=m>0</span>.0402 - val_acc: <span class=m>0</span>.9865
Epoch <span class=m>4</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 238s - loss: <span class=m>0</span>.0692 - acc: <span class=m>0</span>.9792 - val_loss: <span class=m>0</span>.0362 - val_acc: <span class=m>0</span>.9874
Epoch <span class=m>5</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 241s - loss: <span class=m>0</span>.0614 - acc: <span class=m>0</span>.9821 - val_loss: <span class=m>0</span>.0370 - val_acc: <span class=m>0</span>.9879
Epoch <span class=m>6</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 245s - loss: <span class=m>0</span>.0547 - acc: <span class=m>0</span>.9839 - val_loss: <span class=m>0</span>.0319 - val_acc: <span class=m>0</span>.9885
Epoch <span class=m>7</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 248s - loss: <span class=m>0</span>.0517 - acc: <span class=m>0</span>.9840 - val_loss: <span class=m>0</span>.0293 - val_acc: <span class=m>0</span>.9900
Epoch <span class=m>8</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 256s - loss: <span class=m>0</span>.0465 - acc: <span class=m>0</span>.9863 - val_loss: <span class=m>0</span>.0294 - val_acc: <span class=m>0</span>.9905
Epoch <span class=m>9</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 264s - loss: <span class=m>0</span>.0422 - acc: <span class=m>0</span>.9870 - val_loss: <span class=m>0</span>.0276 - val_acc: <span class=m>0</span>.9902
Epoch <span class=m>10</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 263s - loss: <span class=m>0</span>.0423 - acc: <span class=m>0</span>.9875 - val_loss: <span class=m>0</span>.0287 - val_acc: <span class=m>0</span>.9902
Epoch <span class=m>11</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 262s - loss: <span class=m>0</span>.0389 - acc: <span class=m>0</span>.9884 - val_loss: <span class=m>0</span>.0291 - val_acc: <span class=m>0</span>.9898
Epoch <span class=m>12</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 270s - loss: <span class=m>0</span>.0377 - acc: <span class=m>0</span>.9885 - val_loss: <span class=m>0</span>.0272 - val_acc: <span class=m>0</span>.9910
Test loss: <span class=m>0</span>.0271551907005
Test accuracy: <span class=m>0</span>.991</code></pre></table></div></div><p>我们现在使用以下命令行利用带 Theano 的后端的 Keras 在 GPU 和 cuDNN 环境下训练卷积神经网络:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>THEANO_FLAGS</span><span class=o>=</span>%THEANO_FLAGS_GPU%
<span class=o>(</span>dlwin36<span class=o>)</span> $ python mnist_cnn.py
Using Theano backend.
Can not use cuDNN on context None: Disabled by dnn.enabled flag
Preallocating <span class=m>9830</span>/12288 Mb <span class=o>(</span><span class=m>0</span>.800000<span class=o>)</span> on cuda0
Mapped name None to device cuda0: GeForce GTX TITAN X <span class=o>(</span><span class=m>0000</span>:03:00.0<span class=o>)</span>
x_train shape: <span class=o>(</span><span class=m>60000</span>, <span class=m>28</span>, <span class=m>28</span>, <span class=m>1</span><span class=o>)</span>
<span class=m>60000</span> train samples
<span class=m>10000</span> <span class=nb>test</span> samples
Train on <span class=m>60000</span> samples, validate on <span class=m>10000</span> samples
Epoch <span class=m>1</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 48s - loss: <span class=m>0</span>.3258 - acc: <span class=m>0</span>.9023 - val_loss: <span class=m>0</span>.0752 - val_acc: <span class=m>0</span>.9761
Epoch <span class=m>2</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.1108 - acc: <span class=m>0</span>.9669 - val_loss: <span class=m>0</span>.0511 - val_acc: <span class=m>0</span>.9833
Epoch <span class=m>3</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0862 - acc: <span class=m>0</span>.9743 - val_loss: <span class=m>0</span>.0438 - val_acc: <span class=m>0</span>.9845
Epoch <span class=m>4</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0726 - acc: <span class=m>0</span>.9786 - val_loss: <span class=m>0</span>.0422 - val_acc: <span class=m>0</span>.9860
Epoch <span class=m>5</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0621 - acc: <span class=m>0</span>.9818 - val_loss: <span class=m>0</span>.0351 - val_acc: <span class=m>0</span>.9885
Epoch <span class=m>6</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0575 - acc: <span class=m>0</span>.9828 - val_loss: <span class=m>0</span>.0346 - val_acc: <span class=m>0</span>.9878
Epoch <span class=m>7</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0523 - acc: <span class=m>0</span>.9843 - val_loss: <span class=m>0</span>.0325 - val_acc: <span class=m>0</span>.9894
Epoch <span class=m>8</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0478 - acc: <span class=m>0</span>.9861 - val_loss: <span class=m>0</span>.0313 - val_acc: <span class=m>0</span>.9894
Epoch <span class=m>9</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0444 - acc: <span class=m>0</span>.9869 - val_loss: <span class=m>0</span>.0286 - val_acc: <span class=m>0</span>.9906
Epoch <span class=m>10</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0412 - acc: <span class=m>0</span>.9879 - val_loss: <span class=m>0</span>.0287 - val_acc: <span class=m>0</span>.9904
Epoch <span class=m>11</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0393 - acc: <span class=m>0</span>.9885 - val_loss: <span class=m>0</span>.0286 - val_acc: <span class=m>0</span>.9904
Epoch <span class=m>12</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 47s - loss: <span class=m>0</span>.0367 - acc: <span class=m>0</span>.9885 - val_loss: <span class=m>0</span>.0271 - val_acc: <span class=m>0</span>.9919
Test loss: <span class=m>0</span>.0271264006825
Test accuracy: <span class=m>0</span>.9919</code></pre></table></div></div><p>That is quite an improvement over the CPU-only version already. Without cuDNN, each epoch takes about 47s on this particular machine. If you install <a href=https://www.techpowerup.com/downloads/SysInfo/GPU-Z/ target=_blank>TechPowerUp&rsquo;s GPU-Z</a>, you can track how well the GPU is being leveraged. Here, in the case of this convnet (no cuDNN), we max out at 97% GPU usage on average:<p><img src=/img/post-content/deeplearning-on-windows/mnist_cnn_gpu_usage_theano-2017-07.png alt><p>Finally, use the following commands to train the convnet using the Theano backend in GPU mode with cuDNN:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>THEANO_FLAGS</span><span class=o>=</span>%THEANO_FLAGS_GPU_DNN%
<span class=o>(</span>dlwin36<span class=o>)</span> $ python mnist_cnn.py
Using Theano backend.
Using cuDNN version <span class=m>5110</span> on context None
Preallocating <span class=m>9830</span>/12288 Mb <span class=o>(</span><span class=m>0</span>.800000<span class=o>)</span> on cuda0
Mapped name None to device cuda0: GeForce GTX TITAN X <span class=o>(</span><span class=m>0000</span>:03:00.0<span class=o>)</span>
x_train shape: <span class=o>(</span><span class=m>60000</span>, <span class=m>28</span>, <span class=m>28</span>, <span class=m>1</span><span class=o>)</span>
<span class=m>60000</span> train samples
<span class=m>10000</span> <span class=nb>test</span> samples
Train on <span class=m>60000</span> samples, validate on <span class=m>10000</span> samples
Epoch <span class=m>1</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 17s - loss: <span class=m>0</span>.3219 - acc: <span class=m>0</span>.9003 - val_loss: <span class=m>0</span>.0774 - val_acc: <span class=m>0</span>.9743
Epoch <span class=m>2</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.1108 - acc: <span class=m>0</span>.9674 - val_loss: <span class=m>0</span>.0536 - val_acc: <span class=m>0</span>.9822
Epoch <span class=m>3</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0832 - acc: <span class=m>0</span>.9766 - val_loss: <span class=m>0</span>.0434 - val_acc: <span class=m>0</span>.9862
Epoch <span class=m>4</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0694 - acc: <span class=m>0</span>.9795 - val_loss: <span class=m>0</span>.0382 - val_acc: <span class=m>0</span>.9876
Epoch <span class=m>5</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0605 - acc: <span class=m>0</span>.9819 - val_loss: <span class=m>0</span>.0353 - val_acc: <span class=m>0</span>.9884
Epoch <span class=m>6</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0533 - acc: <span class=m>0</span>.9836 - val_loss: <span class=m>0</span>.0360 - val_acc: <span class=m>0</span>.9883
Epoch <span class=m>7</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0482 - acc: <span class=m>0</span>.9859 - val_loss: <span class=m>0</span>.0305 - val_acc: <span class=m>0</span>.9897
Epoch <span class=m>8</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0452 - acc: <span class=m>0</span>.9865 - val_loss: <span class=m>0</span>.0295 - val_acc: <span class=m>0</span>.9911
Epoch <span class=m>9</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0414 - acc: <span class=m>0</span>.9878 - val_loss: <span class=m>0</span>.0315 - val_acc: <span class=m>0</span>.9898
Epoch <span class=m>10</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0386 - acc: <span class=m>0</span>.9886 - val_loss: <span class=m>0</span>.0282 - val_acc: <span class=m>0</span>.9911
Epoch <span class=m>11</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0378 - acc: <span class=m>0</span>.9887 - val_loss: <span class=m>0</span>.0306 - val_acc: <span class=m>0</span>.9904
Epoch <span class=m>12</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 16s - loss: <span class=m>0</span>.0354 - acc: <span class=m>0</span>.9893 - val_loss: <span class=m>0</span>.0296 - val_acc: <span class=m>0</span>.9898
Test loss: <span class=m>0</span>.0296215178292
Test accuracy: <span class=m>0</span>.9898</code></pre></table></div></div><p>An even bigger speed improvement, at about the same GPU usage:<p><img src=/img/post-content/deeplearning-on-windows/mnist_cnn_gpu_cudnn_usage_theano-2017-07.png alt><h4 id=2-使用-tensorflow-后端的-keras>2. 使用 TensorFlow 后端的 Keras</h4><p>为了激活和测试 TensorFlow 后端,我们需要使用以下命令行:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>KERAS_BACKEND</span><span class=o>=</span>tensorflow
<span class=o>(</span>dlwin36<span class=o>)</span> $ python mnist_cnn.py
Using TensorFlow backend.
x_train shape: <span class=o>(</span><span class=m>60000</span>, <span class=m>28</span>, <span class=m>28</span>, <span class=m>1</span><span class=o>)</span>
<span class=m>60000</span> train samples
<span class=m>10000</span> <span class=nb>test</span> samples
Train on <span class=m>60000</span> samples, validate on <span class=m>10000</span> samples
Epoch <span class=m>1</span>/12
<span class=m>2017</span>-06-30 <span class=m>12</span>:49:22.005585: W c:<span class=se>\t</span>f_jenkins<span class=se>\h</span>ome<span class=se>\w</span>orkspace<span class=se>\r</span>elease-win<span class=se>\m\w</span>indows-gpu<span class=se>\p</span>y<span class=se>\3</span><span class=m>6</span><span class=se>\t</span>ensorflow<span class=se>\c</span>ore<span class=se>\p</span>latform<span class=se>\c</span>pu_feature_guard.cc:45<span class=o>]</span> The TensorFlow library wasn<span class=s1>&#39;t compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
</span><span class=s1>2017-06-30 12:49:22.005767: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;</span>t compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
<span class=m>2017</span>-06-30 <span class=m>12</span>:49:22.005996: W c:<span class=se>\t</span>f_jenkins<span class=se>\h</span>ome<span class=se>\w</span>orkspace<span class=se>\r</span>elease-win<span class=se>\m\w</span>indows-gpu<span class=se>\p</span>y<span class=se>\3</span><span class=m>6</span><span class=se>\t</span>ensorflow<span class=se>\c</span>ore<span class=se>\p</span>latform<span class=se>\c</span>pu_feature_guard.cc:45<span class=o>]</span> The TensorFlow library wasn<span class=s1>&#39;t compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
</span><span class=s1>2017-06-30 12:49:22.006181: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;</span>t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
<span class=m>2017</span>-06-30 <span class=m>12</span>:49:22.006361: W c:<span class=se>\t</span>f_jenkins<span class=se>\h</span>ome<span class=se>\w</span>orkspace<span class=se>\r</span>elease-win<span class=se>\m\w</span>indows-gpu<span class=se>\p</span>y<span class=se>\3</span><span class=m>6</span><span class=se>\t</span>ensorflow<span class=se>\c</span>ore<span class=se>\p</span>latform<span class=se>\c</span>pu_feature_guard.cc:45<span class=o>]</span> The TensorFlow library wasn<span class=s1>&#39;t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
</span><span class=s1>2017-06-30 12:49:22.006539: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;</span>t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
<span class=m>2017</span>-06-30 <span class=m>12</span>:49:22.006717: W c:<span class=se>\t</span>f_jenkins<span class=se>\h</span>ome<span class=se>\w</span>orkspace<span class=se>\r</span>elease-win<span class=se>\m\w</span>indows-gpu<span class=se>\p</span>y<span class=se>\3</span><span class=m>6</span><span class=se>\t</span>ensorflow<span class=se>\c</span>ore<span class=se>\p</span>latform<span class=se>\c</span>pu_feature_guard.cc:45<span class=o>]</span> The TensorFlow library wasn<span class=s1>&#39;t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
</span><span class=s1>2017-06-30 12:49:22.006897: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;</span>t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
<span class=m>2017</span>-06-30 <span class=m>12</span>:49:22.453483: I c:<span class=se>\t</span>f_jenkins<span class=se>\h</span>ome<span class=se>\w</span>orkspace<span class=se>\r</span>elease-win<span class=se>\m\w</span>indows-gpu<span class=se>\p</span>y<span class=se>\3</span><span class=m>6</span><span class=se>\t</span>ensorflow<span class=se>\c</span>ore<span class=se>\c</span>ommon_runtime<span class=se>\g</span>pu<span class=se>\g</span>pu_device.cc:940<span class=o>]</span> Found device <span class=m>0</span> with properties:
name: GeForce GTX TITAN X
major: <span class=m>5</span> minor: <span class=m>2</span> memoryClockRate <span class=o>(</span>GHz<span class=o>)</span> <span class=m>1</span>.076
pciBusID <span class=m>0000</span>:03:00.0
Total memory: <span class=m>12</span>.00GiB
Free memory: <span class=m>10</span>.06GiB
<span class=m>2017</span>-06-30 <span class=m>12</span>:49:22.454375: I c:<span class=se>\t</span>f_jenkins<span class=se>\h</span>ome<span class=se>\w</span>orkspace<span class=se>\r</span>elease-win<span class=se>\m\w</span>indows-gpu<span class=se>\p</span>y<span class=se>\3</span><span class=m>6</span><span class=se>\t</span>ensorflow<span class=se>\c</span>ore<span class=se>\c</span>ommon_runtime<span class=se>\g</span>pu<span class=se>\g</span>pu_device.cc:961<span class=o>]</span> DMA: <span class=m>0</span>
<span class=m>2017</span>-06-30 <span class=m>12</span>:49:22.454489: I c:<span class=se>\t</span>f_jenkins<span class=se>\h</span>ome<span class=se>\w</span>orkspace<span class=se>\r</span>elease-win<span class=se>\m\w</span>indows-gpu<span class=se>\p</span>y<span class=se>\3</span><span class=m>6</span><span class=se>\t</span>ensorflow<span class=se>\c</span>ore<span class=se>\c</span>ommon_runtime<span class=se>\g</span>pu<span class=se>\g</span>pu_device.cc:971<span class=o>]</span> <span class=m>0</span>:   Y
<span class=m>2017</span>-06-30 <span class=m>12</span>:49:22.454624: I c:<span class=se>\t</span>f_jenkins<span class=se>\h</span>ome<span class=se>\w</span>orkspace<span class=se>\r</span>elease-win<span class=se>\m\w</span>indows-gpu<span class=se>\p</span>y<span class=se>\3</span><span class=m>6</span><span class=se>\t</span>ensorflow<span class=se>\c</span>ore<span class=se>\c</span>ommon_runtime<span class=se>\g</span>pu<span class=se>\g</span>pu_device.cc:1030<span class=o>]</span> Creating TensorFlow device <span class=o>(</span>/gpu:0<span class=o>)</span> -&gt; <span class=o>(</span>device: <span class=m>0</span>, name: GeForce G
TX TITAN X, pci bus id: <span class=m>0000</span>:03:00.0<span class=o>)</span>
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.3355 - acc: <span class=m>0</span>.8979 - val_loss: <span class=m>0</span>.0749 - val_acc: <span class=m>0</span>.9760
Epoch <span class=m>2</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.1134 - acc: <span class=m>0</span>.9667 - val_loss: <span class=m>0</span>.0521 - val_acc: <span class=m>0</span>.9825
Epoch <span class=m>3</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0863 - acc: <span class=m>0</span>.9745 - val_loss: <span class=m>0</span>.0436 - val_acc: <span class=m>0</span>.9854
Epoch <span class=m>4</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0722 - acc: <span class=m>0</span>.9787 - val_loss: <span class=m>0</span>.0381 - val_acc: <span class=m>0</span>.9872
Epoch <span class=m>5</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0636 - acc: <span class=m>0</span>.9811 - val_loss: <span class=m>0</span>.0339 - val_acc: <span class=m>0</span>.9880
Epoch <span class=m>6</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0552 - acc: <span class=m>0</span>.9838 - val_loss: <span class=m>0</span>.0328 - val_acc: <span class=m>0</span>.9888
Epoch <span class=m>7</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0515 - acc: <span class=m>0</span>.9851 - val_loss: <span class=m>0</span>.0318 - val_acc: <span class=m>0</span>.9893
Epoch <span class=m>8</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0479 - acc: <span class=m>0</span>.9862 - val_loss: <span class=m>0</span>.0311 - val_acc: <span class=m>0</span>.9891
Epoch <span class=m>9</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0441 - acc: <span class=m>0</span>.9870 - val_loss: <span class=m>0</span>.0310 - val_acc: <span class=m>0</span>.9898
Epoch <span class=m>10</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0407 - acc: <span class=m>0</span>.9871 - val_loss: <span class=m>0</span>.0302 - val_acc: <span class=m>0</span>.9903
Epoch <span class=m>11</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0405 - acc: <span class=m>0</span>.9877 - val_loss: <span class=m>0</span>.0309 - val_acc: <span class=m>0</span>.9892
Epoch <span class=m>12</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 5s - loss: <span class=m>0</span>.0373 - acc: <span class=m>0</span>.9886 - val_loss: <span class=m>0</span>.0309 - val_acc: <span class=m>0</span>.9898
Test loss: <span class=m>0</span>.0308696583555
Test accuracy: <span class=m>0</span>.9898</code></pre></table></div></div><blockquote><p>Note: The warnings at the beginning are annoying, but so far there is <a href=https://www.tensorflow.org/install/install_sources target=_blank>no supported way</a> of building Tensorflow on Windows with those optimizations, so we have to stay put and simply ignore them. Hopefully that will be <a href=https://github.com/tensorflow/tensorflow/issues/7778 target=_blank>fixed</a> <a href=https://github.com/tensorflow/tensorflow/issues/7257 target=_blank>soon</a> so people don&rsquo;t have to <a href=https://github.com/tensorflow/tensorflow/tree/v1.1.0/tensorflow/contrib/cmake target=_blank>build Tensorflow</a> for <a href=https://github.com/yaroslavvb/tensorflow-community-wheels target=_blank>themselves</a> because that&rsquo;s <a href="https://stackoverflow.com/questions/42603407/how-to-compile-tensor-flow-with-sse-and-and-avx-instructions-on-windows?noredirect=1&amp;lq=1" target=_blank>quite</a> <a href="https://stackoverflow.com/questions/44071608/compiling-tensorflow-with-cmake-on-windows-fails-with-file-version-info-cc-not-f?noredirect=1&amp;lq=1" target=_blank>tricky</a>.</blockquote><p>我们看到使用 TensorFlow 后端要比 Theano 后端在该任务上快 3 倍左右,它们都是用了 GPU 和 cuDNN 加速.这可能是因为在该测试中它们有相同的通道等级(channel ordering),但实际上两个平台在这一点是不一样的.因此,程序可能强制 Theano 后端重新排序数据而造成性能上的差异.但在该案例下,TensorFlow 在 GPU 上的负载一直没有超过 70%.<p><img src=/img/post-content/deeplearning-on-windows/mnist_cnn_gpu_cudnn_usage_tensorflow-2017-07.png alt><h4 id=3-使用-cntk-后端的-keras>3. 使用 CNTK 后端的 Keras</h4><p>为了激活和测试 CNTK 后算,我们需要使用以下命令行:<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=o>(</span>dlwin36<span class=o>)</span> $ <span class=nb>set</span> <span class=nv>KERAS_BACKEND</span><span class=o>=</span>cntk
<span class=o>(</span>dlwin36<span class=o>)</span> $ python mnist_cnn.py
Using CNTK backend
Selected GPU<span class=o>[</span><span class=m>0</span><span class=o>]</span> GeForce GTX TITAN X as the process wide default device.
x_train shape: <span class=o>(</span><span class=m>60000</span>, <span class=m>28</span>, <span class=m>28</span>, <span class=m>1</span><span class=o>)</span>
<span class=m>60000</span> train samples
<span class=m>10000</span> <span class=nb>test</span> samples
Train on <span class=m>60000</span> samples, validate on <span class=m>10000</span> samples
Epoch <span class=m>1</span>/12
e:<span class=se>\t</span>oolkits.win<span class=se>\a</span>naconda3-4.4.0<span class=se>\e</span>nvs<span class=se>\d</span>lwin36<span class=se>\l</span>ib<span class=se>\s</span>ite-packages<span class=se>\c</span>ntk<span class=se>\c</span>ore.py:351: UserWarning: your data is of <span class=nb>type</span> <span class=s2>&#34;float64&#34;</span>, but your input variable <span class=o>(</span>uid <span class=s2>&#34;Input113&#34;</span><span class=o>)</span> expects <span class=s2>&#34;&lt;class &#39;numpy.float32&#39;&gt;&#34;</span>. Please convert your data beforehand to speed up training.
  <span class=o>(</span>sample.dtype, var.uid, str<span class=o>(</span>var.dtype<span class=o>)))</span>
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.3275 - acc: <span class=m>0</span>.8991 - val_loss: <span class=m>0</span>.0754 - val_acc: <span class=m>0</span>.9749
Epoch <span class=m>2</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 7s - loss: <span class=m>0</span>.1114 - acc: <span class=m>0</span>.9662 - val_loss: <span class=m>0</span>.0513 - val_acc: <span class=m>0</span>.9841
Epoch <span class=m>3</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 7s - loss: <span class=m>0</span>.0862 - acc: <span class=m>0</span>.9750 - val_loss: <span class=m>0</span>.0429 - val_acc: <span class=m>0</span>.9859
Epoch <span class=m>4</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 7s - loss: <span class=m>0</span>.0721 - acc: <span class=m>0</span>.9784 - val_loss: <span class=m>0</span>.0373 - val_acc: <span class=m>0</span>.9868
Epoch <span class=m>5</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 7s - loss: <span class=m>0</span>.0649 - acc: <span class=m>0</span>.9803 - val_loss: <span class=m>0</span>.0339 - val_acc: <span class=m>0</span>.9878
Epoch <span class=m>6</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.0580 - acc: <span class=m>0</span>.9831 - val_loss: <span class=m>0</span>.0337 - val_acc: <span class=m>0</span>.9890
Epoch <span class=m>7</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.0529 - acc: <span class=m>0</span>.9846 - val_loss: <span class=m>0</span>.0326 - val_acc: <span class=m>0</span>.9895
Epoch <span class=m>8</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.0483 - acc: <span class=m>0</span>.9858 - val_loss: <span class=m>0</span>.0307 - val_acc: <span class=m>0</span>.9897
Epoch <span class=m>9</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.0456 - acc: <span class=m>0</span>.9864 - val_loss: <span class=m>0</span>.0299 - val_acc: <span class=m>0</span>.9898
Epoch <span class=m>10</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.0407 - acc: <span class=m>0</span>.9875 - val_loss: <span class=m>0</span>.0274 - val_acc: <span class=m>0</span>.9906
Epoch <span class=m>11</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.0405 - acc: <span class=m>0</span>.9883 - val_loss: <span class=m>0</span>.0276 - val_acc: <span class=m>0</span>.9904
Epoch <span class=m>12</span>/12
<span class=m>60000</span>/60000 <span class=o>[==============================]</span> - 8s - loss: <span class=m>0</span>.0372 - acc: <span class=m>0</span>.9889 - val_loss: <span class=m>0</span>.0274 - val_acc: <span class=m>0</span>.9906
Test loss: <span class=m>0</span>.0274011099327
Test accuracy: <span class=m>0</span>.9906</code></pre></table></div></div><p>在具体的试验中,CNTK 同样也十分快速,并且 GPU 负载达到了 80%.<p><img src=/img/post-content/deeplearning-on-windows/mnist_cnn_gpu_cudnn_usage_cntk-2017-07.png alt><h2 id=最后>最后</h2><h3 id=参考>参考</h3><ol><li><a href=https://datanoord.com/2016/02/02/setup-a-deep-learning-environment-on-windows-theano-keras-with-gpu-enabled/ target=_blank>Setup a Deep Learning Environment on Windows (Theano &amp; Keras with GPU Enabled)</a>, by Ayse Elvan Aydemir<li><a href=http://deeplearning.net/software/theano_versions/dev/install_windows.html##install-windows target=_blank>Installation of Theano on Windows</a>, by Theano team<li><a href=https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/13973/a-few-tips-to-install-theano-on-windows-64-bits target=_blank>A few tips to install theano on Windows, 64 bits</a>, by Kagglers<li><a href=http://stackoverflow.com/questions/34097988/how-do-i-install-keras-and-theano-in-anaconda-python-2-7-on-windows target=_blank>How do I install Keras and Theano in Anaconda Python 2.7 on Windows?</a>, by S.O. contributors</ol><h3 id=致谢>致谢&hellip;</h3><p>感谢<a href=https://github.com/apacha target=_blank>Alexander Pacha</a> 数次更新本教程并且将TensorFlow的内容纳入.
感谢<a href=https://www.kaggle.com/vincentl target=_blank>Kaggler Vincent L.</a>建议将<code>dnn.conv.algo_bwd_filter=deterministic,dnn.conv.algo_bwd_data=deterministic</code>加入到<code>THEANO_FLAGS_GPU_DNN</code>来提升<code>reproducibility with no observable impact on performance</code>.<h3 id=推荐阅读>推荐阅读</h3><p>Alec Radford的<code>利用Python进行深度学习入门</code>:<ul><li><a href="https://www.youtube.com/watch?v=S75EdAcXHKk" target=_blank>Introduction to Deep Learning with Python</a><li><a href=http://slidesha.re/1zs9M11 target=_blank>deep-learning-with-python-and-the-theano-library</a><li><a href=https://github.com/Newmu/Theano-Tutorials target=_blank>Theano-Tutorials</a></ul><h3 id=作者信息>作者信息</h3><ul><li>原文作者详细信息:<a href=https://www.linkedin.com/in/philferriere target=_blank><img src=/img/post-content/deeplearning-on-windows/LinkedInDev.png alt=https://www.linkedin.com/in/philferriere></a><li><a href=http://mp.weixin.qq.com/s/vhBOrR6uTL2vGXnYC8BS1w target=_blank>机器之心原文链接</a></ul><h3 id=补充>补充</h3><p>严格安照教程来,本人在安装时自作主张的使用了 <code>CUDA 9.0</code> ,完全无法使用GPU(TensorFlow-GPU最新版1.4不支持),以及theano的安装好像没有原文那么简单,CNTK可以安装最新版,可以运行.</p><ins class=adsbygoogle style=display:block;text-align:center data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-4469282388984999 data-ad-slot=5357438236></ins><ins class=adsbygoogle style=display:block data-ad-client=ca-pub-4469282388984999 data-ad-slot=5625031544 data-ad-format=auto data-full-width-responsive=true></ins></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>Quanyin</span><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2020-05-07</span><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content>本博客所有文章除特别声明外，均采用 <a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>(CC) BY-NC-SA 4.0 </a>许可协议。转载请注明作者和出处并告知</span></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/img/reward/WechatPay.png>
<span>微信打赏</span></label>
<label class=qr-code-image for=reward><img class=image src=/img/reward/AliPay.png>
<span>支付宝打赏</span></label></div></div><footer class=post-footer><div class=post-tags><a href=/tags/deep-learning/>Deep-Learning</a>
<a href=/tags/python/>Python</a></div><nav class=post-nav><a class=prev href=/2017/impress-js-for-presentation/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">用网页做Presentation——impress.js</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/2017/create-github-repo-with-cli/><span class="next-text nav-default">三种直接在命令行创建Github仓库的方法</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"/></svg></i></a></nav></footer></article><div class="post bg-white"><div id=comments></div><script src=//cdn1.lncld.net/static/js/3.0.4/av-min.js></script><script src=//unpkg.com/valine/dist/Valine.min.js></script><script>if(window.location.hash){var checkExist=setInterval(function(){if($(window.location.hash).length){$('html, body').animate({scrollTop:$(window.location.hash).offset().top-90},700);clearInterval(checkExist);}},10);}</script><script>new Valine({el:'#comments',appId:'aTnk2nRIOVuFeXVYCRqOhEQ1-MdYXbMMI',appKey:'fPBawjKkMiA8biHbwoDim1mJ',notify:false,verify:false,avatar:'mm',placeholder:'说点什么吧',visitor:false});</script></div></div></div></main><footer id=footer class=footer><div class=icon-links><a href=/index.xml rel="noopener alternate" type=application/rss&#43;xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 0 1 140.501333 140.586667A140.928 140.928.0 0 1 140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2017 -
2020
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>Quanyin</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777v0zm0 0"/></svg></i></div></div><script src=/lib/jquery/jquery-3.2.1.min.js></script><script src=/lib/slideout/slideout-1.0.1.min.js></script><script src=/js/main.js crossorigin=anonymous></script><script src=/js/load-photoswipe.js></script><script src=/lib/photoswipe/photoswipe.min.js></script><script src=/lib/photoswipe/photoswipe-ui-default.min.js></script><script>(adsbygoogle=window.adsbygoogle||[]).push({});</script>