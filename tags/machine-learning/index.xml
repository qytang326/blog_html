<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on 陆家嘴之羊</title><link>/tags/machine-learning/</link><description>Recent content in Machine Learning on 陆家嘴之羊</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>i@imtqy.com (Quanyin)</managingEditor><webMaster>i@imtqy.com (Quanyin)</webMaster><copyright> Quanyin</copyright><lastBuildDate>Fri, 25 May 2018 13:58:45 +0800</lastBuildDate><atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>《统计学习方法》笔记(十二)</title><link>/2018/statistical-learning-method-chpt-12/</link><pubDate>Fri, 25 May 2018 13:58:45 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-12/</guid><description>&lt;p&gt;&lt;img src=&#34;/img/post-content/statistic-learning-method/post-Lihang-chpt12-summary.png&#34; alt=&#34;统计学习方法特点的概括总结&#34; /&gt;&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(十一)</title><link>/2018/statistical-learning-method-chpt-11/</link><pubDate>Fri, 25 May 2018 13:58:43 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-11/</guid><description>&lt;p&gt;条件随机场是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布，其特点是
假设输出随机变量构成马尔科夫随机场，可用于不同的预测问题。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(十)</title><link>/2018/statistical-learning-method-chpt-10/</link><pubDate>Fri, 25 May 2018 13:58:06 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-10/</guid><description>&lt;p&gt;隐马尔可夫模型(HMM)是可用于标注问题的学习模型，描述由隐藏的马尔科夫链随机生成观
测序列的过程，属于生成模型。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(九)</title><link>/2018/statistical-learning-method-chpt-9/</link><pubDate>Fri, 25 May 2018 13:58:03 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-9/</guid><description>&lt;p&gt;EM 算法是一种迭代算法，用于隐含变量的概率模型参数的极大似然估计或极大后验概率估计。
EM 算法的每次迭代由两步组成：E步求期望，M步求极大，因此称为期望极大算法。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(八)</title><link>/2018/statistical-learning-method-chpt-8/</link><pubDate>Fri, 25 May 2018 13:58:01 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-8/</guid><description>&lt;p&gt;提升方法是一种常用的统计学习方法，在分类问题中，它通过改变训练样本的权重，学习多
个分类器，并将这些分类器线性组合，以提高分类的性能。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(七)</title><link>/2018/statistical-learning-method-chpt-7/</link><pubDate>Fri, 25 May 2018 13:57:59 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-7/</guid><description>&lt;p&gt;支持向量机是一种二分类模型，基本模型是定义在特征空间上的间隔最大的线性分类器，间
隔最大使其有别于感知机，而且还包括核技巧，使其成为实质上的非线性分类器。支持向量
机的学习策略是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于求解正则化
的合页损失函数的最小化问题，其学习算法是求解凸二次规划的最优化算法。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(六)</title><link>/2018/statistical-learning-method-chpt-6/</link><pubDate>Fri, 25 May 2018 13:57:56 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-6/</guid><description>&lt;p&gt;Logistic 回归是统计学习中的经典分类方法，最大熵是概率模型学习的一个准则，将其推广
到分类问题上即最大熵模型，二者都属于对数线性模型。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(五)</title><link>/2018/statistical-learning-method-chpt-5/</link><pubDate>Fri, 25 May 2018 13:57:53 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-5/</guid><description>&lt;p&gt;决策树是一种基本的分类和回归方法，决策树模型呈树形结构，在分类问题中表示基于特征
对实例进行分类的过程，可以认为是 if-them 规则的集合，也可以认为是定义在特征空间与
类空间上的条件概率分布，主要优点是模型具有可读性，分类速度快。学习时利用训练数据
，根据损失函数最小化的原则建立决策树模型；预测时，对新的数据利用决策树模型进行分
类。决策树学习包含 3 个步骤：特征选择，决策树的生成和决策树的修剪。决策树的思想来
自于 ID3 算法、C4.5算法(Quinlan,1986，1993)和 CART 算法(Breiman,1984)。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(四)</title><link>/2018/statistical-learning-method-chpt-4/</link><pubDate>Tue, 10 Apr 2018 17:46:54 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-4/</guid><description>&lt;p&gt;朴素贝叶斯法是基于贝叶斯定理与条件独立假设的分类方法。对给定的训练数据集，首先基于
特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入 x ，利用
贝叶斯定理求出后验概率最大的输出 y 。此方法实现简单，学习与预测的效率都很高。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(三)</title><link>/2018/statistical-learning-method-chpt-3/</link><pubDate>Thu, 29 Mar 2018 21:41:22 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-3/</guid><description>&lt;p&gt;k 近邻法是一种基本分类与回归方法，其输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。
k 近邻法利用训练数据集对特征空间进行划分，并作为其分类的 “模型”。k 值的选择，距离度量及
分类决策规则是 k 近邻法的三个基本要素。k 近邻法 1968 年由 Cover 和 Hart 提出。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(二)</title><link>/2018/statistical-learning-method-chpt-2/</link><pubDate>Mon, 26 Mar 2018 16:23:04 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-2/</guid><description>&lt;p&gt;感知机是&lt;code&gt;二分类&lt;/code&gt;的&lt;code&gt;线性&lt;/code&gt;分类模型，其输入为实例的特征向量，输出为实例的类别，取 +1 和 -1 两值。感知机对应于输入空间(特征空间)中将实例划分为正负两例的&lt;code&gt;分离超平面&lt;/code&gt;，属于&lt;code&gt;判别模型&lt;/code&gt;。
感知机学习旨在求出将训练集进行线性划分的分离超平面，导入&lt;code&gt;基于误分类的损失函数&lt;/code&gt;，利用
&lt;code&gt;梯度下降法&lt;/code&gt;对损失函数进行极小化，求得感知机模型。感知机由 Rosonblatt 1957 年提出，是神经网络与支持向量机的基础。&lt;/p&gt;</description></item><item><title>《统计学习方法》笔记(一)</title><link>/2018/statistical-learning-method-chpt-1/</link><pubDate>Tue, 20 Mar 2018 18:25:08 +0800</pubDate><author>i@imtqy.com (Quanyin)</author><guid>/2018/statistical-learning-method-chpt-1/</guid><description>一、统计学习相关概念 1.1 统计学习 统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的门 学科，也称为统计机器学习。 特点 以</description></item></channel></rss>